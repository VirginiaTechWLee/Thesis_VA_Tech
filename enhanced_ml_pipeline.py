import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.model_selection import train_test_split, cross_val_score, StratifiedKFold
from sklearn.ensemble import RandomForestClassifier, VotingClassifier
from sklearn.preprocessing import StandardScaler, MultiLabelBinarizer
from sklearn.metrics import (classification_report, confusion_matrix, accuracy_score,
                           multilabel_confusion_matrix, hamming_loss, jaccard_score,
                           f1_score, precision_score, recall_score)
from sklearn.multioutput import MultiOutputClassifier
import joblib
import os
import warnings
import time
import gc
import psutil
from pathlib import Path
warnings.filterwarnings('ignore')

# Optional imports - handle gracefully if not available
XGBOOST_AVAILABLE = False
try:
    import xgboost as xgb
    XGBOOST_AVAILABLE = True
    print("‚úÖ XGBoost available for enhanced performance")
except ImportError:
    print("‚ö†Ô∏è  XGBoost not available - XGBoost strategy will be disabled")

TENSORFLOW_AVAILABLE = False
try:
    from tensorflow.keras.models import Sequential, load_model
    from tensorflow.keras.layers import Dense, Dropout, BatchNormalization
    from tensorflow.keras.optimizers import Adam
    from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau
    from tensorflow.keras.utils import to_categorical
    import tensorflow as tf
    TENSORFLOW_AVAILABLE = True
    print("‚úÖ TensorFlow available for neural networks")
except ImportError:
    print("‚ö†Ô∏è  TensorFlow not available - Neural Network strategy will be disabled")

class EnhancedMultiCBUSHMLPipeline:
    """
    üöÄ ENHANCED ML pipeline for spacecraft bolt anomaly detection.
    Features: Random Forest + XGBoost + Ensemble + Advanced Multi-Label Methods
    Optimized for massive datasets (11K-111K+ designs) with spacecraft deployment focus.
    """
    
    def __init__(self):
        """Initialize the enhanced ML pipeline for spacecraft applications."""
        self.data = None
        self.X = None
        self.y_multilabel = None
        self.y_single = None
        self.feature_names = None
        self.scaler = StandardScaler()
        self.models = {}
        self.results = {}
        self.classification_mode = None
        self.is_trained = False
        
        # CBUSH mapping (2-10) for spacecraft bolt detection
        self.cbush_numbers = list(range(2, 11))
        
        # Memory management for massive datasets
        self.max_memory_gb = 32.0
        self.enable_memory_management = True
        self.batch_size = 1000
        
        # Enhanced ML strategy options
        self.ml_strategies = {
            'random_forest': 'üå≤ Random Forest (Spacecraft Baseline)',
            'ensemble': 'üéØ Ensemble (Best Overall Performance)'
        }
        
        if XGBOOST_AVAILABLE:
            self.ml_strategies['xgboost'] = 'üöÄ XGBoost (Performance Champion)'
        
        if TENSORFLOW_AVAILABLE:
            self.ml_strategies['neural_network'] = 'üß† Neural Network (Advanced Patterns)'
        
        # Spacecraft deployment thresholds
        self.deployment_thresholds = {
            'exact_match_min': 0.4,        # 40% exact match for spacecraft safety
            'jaccard_min': 0.5,            # 50% label overlap
            'hamming_max': 0.3,            # <30% label errors
            'f1_macro_min': 0.6,           # 60% F1 score
            'deployment_score_min': 60.0   # 60/100 deployment readiness
        }
        
        print("üöÄ Enhanced ML Pipeline Initialized for Spacecraft Bolt Detection")
        print(f"   Available strategies: {list(self.ml_strategies.keys())}")
        print(f"   Memory limit: {self.max_memory_gb}GB")
        print(f"   Spacecraft deployment thresholds configured")
    
    def load_data(self, master_df, chunk_size=None):
        """
        üîß Load and prepare massive datasets for spacecraft ML analysis.
        Enhanced with automatic feature validation and spacecraft-specific preprocessing.
        """
        print("=== LOADING SPACECRAFT BOLT DETECTION DATASET ===")
        
        # Memory check before loading
        self._check_memory_usage("Before data loading")
        
        # Enhanced dataset size handling
        if len(master_df) > 100000:
            print(f"üöÄ MASSIVE DATASET DETECTED ({len(master_df):,} designs)")
            print(f"   Enabling spacecraft-grade memory management")
            self.enable_memory_management = True
        
        self.data = master_df.copy()
        
        # Extract and validate feature columns
        feature_cols = [col for col in self.data.columns 
                       if col.startswith(('ACCE_', 'DISP_'))]
        
        # Validate spacecraft-specific features
        required_features = ['ACCE_T1_Area', 'ACCE_T1_PSD_1', 'DISP_T1_Area']
        missing_features = [f for f in required_features 
                           if not any(col.startswith(f) for col in feature_cols)]
        
        if missing_features:
            print(f"‚ö†Ô∏è  Warning: Missing key spacecraft features: {missing_features}")
        
        # Check memory usage of feature matrix
        estimated_memory_mb = (len(self.data) * len(feature_cols) * 8) / (1024 * 1024)
        print(f"   Estimated feature matrix memory: {estimated_memory_mb:.1f} MB")
        
        if estimated_memory_mb > self.max_memory_gb * 1024 * 0.7:
            print(f"   üîß Large feature matrix detected - enabling batch processing")
        
        self.X = self.data[feature_cols].values
        self.feature_names = feature_cols
        
        print(f"‚úÖ Spacecraft dataset loaded:")
        print(f"   Total designs: {len(self.data):,}")
        print(f"   Features: {len(feature_cols):,}")
        print(f"   Feature types: {self._analyze_feature_types(feature_cols)}")
        
        # Enhanced dataset composition analysis
        self._analyze_dataset_composition()
        
        # Memory management after loading
        self._manage_memory("After spacecraft data loading")
        
        return True
    
    def _analyze_feature_types(self, feature_cols):
        """Analyze types of features for spacecraft monitoring."""
        feature_types = {}
        for col in feature_cols:
            if 'Area' in col:
                feature_types['Energy'] = feature_types.get('Energy', 0) + 1
            elif 'PSD' in col:
                feature_types['Modal'] = feature_types.get('Modal', 0) + 1
            elif 'DISP' in col:
                feature_types['Displacement'] = feature_types.get('Displacement', 0) + 1
            elif 'ACCE' in col:
                feature_types['Acceleration'] = feature_types.get('Acceleration', 0) + 1
        
        return feature_types
    
    def _analyze_dataset_composition(self):
        """Enhanced analysis for spacecraft dataset composition."""
        if 'study_type' in self.data.columns:
            study_composition = self.data['study_type'].value_counts()
            print(f"   üìä Study composition:")
            for study_type, count in study_composition.items():
                print(f"     {study_type}: {count:,} designs ({count/len(self.data)*100:.1f}%)")
        
        # CBUSH involvement analysis for spacecraft
        cbush_involvement = {}
        cbush_total_involvement = 0
        
        for cbush_num in self.cbush_numbers:
            col_name = f'cbush_{cbush_num}_loose'
            if col_name in self.data.columns:
                count = self.data[col_name].sum()
                cbush_involvement[cbush_num] = count
                cbush_total_involvement += count
        
        if cbush_involvement:
            print(f"   üî© CBUSH bolt involvement (loose detections):")
            for cbush_num, count in cbush_involvement.items():
                percentage = (count / len(self.data)) * 100
                print(f"     CBUSH {cbush_num}: {count:,} designs ({percentage:.1f}%)")
            
            avg_loose_per_design = cbush_total_involvement / len(self.data)
            print(f"   üìà Average loose bolts per design: {avg_loose_per_design:.2f}")
    
    def prepare_targets(self, classification_type='auto'):
        """üéØ Prepare targets for spacecraft multi-label bolt detection."""
        print(f"\n=== PREPARING SPACECRAFT TARGETS ({classification_type.upper()}) ===")
        
        if classification_type == 'auto':
            # Enhanced auto-detection for spacecraft applications
            study_types = self.data['study_type'].unique() if 'study_type' in self.data.columns else ['unknown']
            
            # Prioritize multi-label for spacecraft (more realistic)
            if len(study_types) == 1 and 'single' in study_types[0].lower():
                classification_type = 'single'
            else:
                classification_type = 'multilabel'  # Default for spacecraft
            print(f"   üéØ Auto-detected: {classification_type} (spacecraft optimized)")
        
        self.classification_mode = classification_type
        
        if classification_type == 'multilabel':
            # Multi-label classification: predict which CBUSHes are loose
            cbush_cols = [f'cbush_{cbush_num}_loose' for cbush_num in self.cbush_numbers]
            available_cols = [col for col in cbush_cols if col in self.data.columns]
            
            if available_cols:
                self.y_multilabel = self.data[available_cols].values
                print(f"‚úÖ Multi-label spacecraft targets prepared")
                print(f"   Bolt monitoring points: {len(available_cols)} CBUSHes")
                print(f"   CBUSHes monitored: {[col.split('_')[1] for col in available_cols]}")
                
                # Enhanced label distribution analysis
                label_sums = self.y_multilabel.sum(axis=0)
                print(f"   üî© Bolt loosening distribution:")
                
                for i, cbush_num in enumerate(self.cbush_numbers[:len(available_cols)]):
                    percentage = (label_sums[i] / len(self.y_multilabel)) * 100
                    status = "üî¥ HIGH" if percentage > 25 else "üü° MEDIUM" if percentage > 10 else "üü¢ LOW"
                    print(f"     CBUSH {cbush_num}: {label_sums[i]:,} loose ({percentage:.1f}%) {status}")
                
                # Spacecraft-specific class imbalance analysis
                max_imbalance = max(label_sums) / (min(label_sums) + 1)
                if max_imbalance > 10:
                    print(f"   ‚ö†Ô∏è  CLASS IMBALANCE DETECTED (ratio: {max_imbalance:.1f})")
                    print(f"   üîß Recommendation: Use balanced class weights for spacecraft safety")
                
                # Multi-failure analysis (critical for spacecraft)
                multi_failure_count = np.sum(self.y_multilabel.sum(axis=1) > 1)
                multi_failure_rate = multi_failure_count / len(self.y_multilabel)
                print(f"   üö® Multi-bolt failures: {multi_failure_count:,} designs ({multi_failure_rate:.1%})")
                
                if multi_failure_rate > 0.1:
                    print(f"   üîß High multi-failure rate detected - ensemble methods recommended")
                
            else:
                print("‚ùå No multi-label columns found")
                return False
                
        elif classification_type == 'single':
            # Traditional single-CBUSH classification (legacy spacecraft mode)
            if 'varied_cbush' in self.data.columns:
                self.y_single = self.data['varied_cbush'].values
                print(f"‚úÖ Single-CBUSH spacecraft targets prepared")
                print(f"   Total samples: {len(self.y_single):,}")
                
                # Enhanced class distribution analysis
                unique_classes, counts = np.unique(self.y_single, return_counts=True)
                print(f"   üî© Monitored CBUSHes: {sorted(unique_classes)}")
                print(f"   Class distribution:")
                for cls, count in zip(unique_classes, counts):
                    percentage = (count / len(self.y_single)) * 100
                    print(f"     CBUSH {cls}: {count:,} samples ({percentage:.1f}%)")
                    
                # Check for class balance (important for spacecraft safety)
                balance_ratio = max(counts) / min(counts) if min(counts) > 0 else float('inf')
                if balance_ratio > 5:
                    print(f"   ‚ö†Ô∏è  Class imbalance detected (ratio: {balance_ratio:.1f})")
            else:
                print("‚ùå No single-CBUSH column found")
                return False
        
        return True
    
    def train_spacecraft_ml_trinity(self, **kwargs):
        """
        üöÄ Train the Spacecraft ML Trinity: Random Forest + XGBoost + Ensemble
        Optimized for spacecraft bolt detection with deployment readiness assessment.
        """
        print("\nüöÄ TRAINING SPACECRAFT ML TRINITY")
        print("=" * 60)
        
        if self.X is None or (self.y_multilabel is None and self.y_single is None):
            raise ValueError("Data not prepared. Call load_data() and prepare_targets() first.")
        
        # Prepare training data with spacecraft-optimized split
        X_train, X_test, y_train, y_test = self._prepare_spacecraft_training_data()
        
        training_results = {}
        
        # üå≤ 1. Random Forest (Spacecraft Baseline)
        print("\nüå≤ TRAINING RANDOM FOREST (SPACECRAFT BASELINE)")
        print("-" * 50)
        rf_model = self._train_spacecraft_random_forest(X_train, X_test, y_train, y_test, **kwargs)
        if rf_model:
            training_results['random_forest'] = rf_model
        
        # üöÄ 2. XGBoost (Performance Champion)
        if XGBOOST_AVAILABLE:
            print("\nüöÄ TRAINING XGBOOST (PERFORMANCE CHAMPION)")
            print("-" * 50)
            xgb_model = self._train_spacecraft_xgboost(X_train, X_test, y_train, y_test, **kwargs)
            if xgb_model:
                training_results['xgboost'] = xgb_model
        
        # üß† 3. Neural Network (if available)
        if TENSORFLOW_AVAILABLE:
            print("\nüß† TRAINING NEURAL NETWORK (ADVANCED PATTERNS)")
            print("-" * 50)
            nn_model = self._train_spacecraft_neural_network(X_train, X_test, y_train, y_test, **kwargs)
            if nn_model:
                training_results['neural_network'] = nn_model
        
        # üéØ 4. Ensemble (Best of All Worlds)
        if len(training_results) >= 2:
            print("\nüéØ TRAINING ENSEMBLE (BEST OF ALL WORLDS)")
            print("-" * 50)
            ensemble_model = self._train_spacecraft_ensemble(X_train, X_test, y_train, y_test, training_results)
            if ensemble_model:
                training_results['ensemble'] = ensemble_model
        
        # üìä Performance Summary and Deployment Assessment
        self._spacecraft_deployment_assessment(training_results)
        
        self.is_trained = True
        return training_results
    
    def _prepare_spacecraft_training_data(self):
        """Prepare training data with spacecraft-specific considerations."""
        # Choose target and apply spacecraft-optimized scaling
        if self.classification_mode == 'multilabel':
            y_target = self.y_multilabel
        else:
            y_target = self.y_single
        
        # Spacecraft-optimized train/test split
        test_size = min(0.2, max(0.05, 10000 / len(self.X)))  # Adaptive for massive datasets
        
        if self.classification_mode == 'multilabel':
            # Random split for multi-label (stratification is complex)
            X_train, X_test, y_train, y_test = train_test_split(
                self.X, y_target, test_size=test_size, random_state=42
            )
        else:
            # Stratified split for single-label
            X_train, X_test, y_train, y_test = train_test_split(
                self.X, y_target, test_size=test_size, random_state=42, stratify=y_target
            )
        
        print(f"üîß Spacecraft data preparation:")
        print(f"   Training set: {len(X_train):,} samples ({len(X_train)/len(self.X):.1%})")
        print(f"   Test set: {len(X_test):,} samples ({len(X_test)/len(self.X):.1%})")
        
        # üîß CRITICAL: Feature scaling for spacecraft sensors
        print(f"‚≠ê APPLYING SPACECRAFT FEATURE SCALING")
        
        # Check feature scale before scaling
        feature_mins = self.X.min(axis=0)
        feature_maxs = self.X.max(axis=0)
        scale_range = feature_maxs - feature_mins
        
        print(f"   Before scaling: Range {feature_mins.min():.2e} to {feature_maxs.max():.2e}")
        print(f"   Scale range spans: {scale_range.max() / (scale_range.min() + 1e-10):.1e} orders of magnitude")
        
        X_train_scaled = self.scaler.fit_transform(X_train)
        X_test_scaled = self.scaler.transform(X_test)
        
        print(f"   After scaling: Range {X_train_scaled.min():.2f} to {X_train_scaled.max():.2f}")
        print(f"   ‚úÖ Feature scaling complete - ready for spacecraft ML")
        
        return X_train_scaled, X_test_scaled, y_train, y_test
    
    def _train_spacecraft_random_forest(self, X_train, X_test, y_train, y_test, **kwargs):
        """Train Random Forest optimized for spacecraft bolt detection."""
        start_time = time.time()
        
        # Spacecraft-optimized Random Forest parameters
        spacecraft_params = {
            'n_estimators': 200,           # Good balance for spacecraft
            'max_depth': 15,               # Prevent overfitting
            'min_samples_split': 10,       # Conservative for safety
            'min_samples_leaf': 5,         # Conservative for safety
            'class_weight': 'balanced',    # Handle class imbalance
            'random_state': 42,           # Reproducibility for spacecraft
            'n_jobs': 4,                  # Windows-safe parallelization
            'max_features': 'sqrt',       # Good default for high dimensions
            'bootstrap': True,            # Enable bagging
            'oob_score': True            # Out-of-bag scoring for validation
        }
        spacecraft_params.update(kwargs.get('random_forest', {}))
        
        # Adjust for massive datasets
        if len(X_train) > 100000:
            print(f"   üìä Massive dataset optimization for {len(X_train):,} samples")
            spacecraft_params.update({
                'n_estimators': 150,       # Reduce for speed
                'max_depth': 12,          # Reduce depth
                'min_samples_split': 20,   # Increase for speed
                'min_samples_leaf': 10,    # Increase for speed
                'max_samples': 0.7,       # Bootstrap smaller samples
                'n_jobs': 2               # Conservative for memory
            })
        
        # Create model based on classification mode
        if self.classification_mode == 'multilabel':
            rf = MultiOutputClassifier(RandomForestClassifier(**spacecraft_params))
        else:
            rf = RandomForestClassifier(**spacecraft_params)
        
        print(f"   üå≤ Training Random Forest with spacecraft parameters...")
        print(f"   Parameters: {len(X_train):,} samples, {spacecraft_params['n_estimators']} trees")
        
        try:
            rf.fit(X_train, y_train)
            print("   ‚úÖ Random Forest training completed successfully!")
        except Exception as e:
            print(f"   ‚ùå Random Forest training failed: {e}")
            return None
        
        training_time = time.time() - start_time
        
        # Make predictions and calculate metrics
        print(f"   üîÑ Generating spacecraft predictions...")
        y_pred = rf.predict(X_test)
        
        # Calculate spacecraft-specific metrics
        metrics = self._calculate_spacecraft_metrics(y_test, y_pred, 'Random Forest')
        metrics['training_time'] = training_time
        metrics['model_params'] = spacecraft_params
        metrics['oob_score'] = getattr(rf, 'oob_score_', None)
        
        # Store model and results
        self.models['random_forest'] = rf
        self.results['random_forest'] = metrics
        
        # Memory cleanup
        self._manage_memory("After Random Forest training")
        
        print(f"   ‚úÖ Random Forest completed in {training_time:.1f}s")
        print(f"   üìä Deployment Score: {metrics.get('deployment_score', 0):.1f}/100")
        self._print_spacecraft_metrics(metrics)
        
        return rf
    
    def _train_spacecraft_xgboost(self, X_train, X_test, y_train, y_test, **kwargs):
        """Train XGBoost optimized for spacecraft bolt detection."""
        start_time = time.time()
        
        # Spacecraft-optimized XGBoost parameters
        spacecraft_params = {
            'n_estimators': 200,           # Good performance balance
            'max_depth': 10,               # Prevent overfitting
            'learning_rate': 0.1,          # Conservative learning rate
            'subsample': 0.8,              # Bootstrap for robustness
            'colsample_bytree': 0.8,       # Feature bagging
            'reg_alpha': 0.1,              # L1 regularization
            'reg_lambda': 0.1,             # L2 regularization
            'random_state': 42,           # Reproducibility
            'n_jobs': 4,                  # Windows-safe parallelization
            'eval_metric': 'logloss',     # Good for classification
            'verbosity': 0                # Quiet training
        }
        spacecraft_params.update(kwargs.get('xgboost', {}))
        
        # Adjust for massive datasets
        if len(X_train) > 100000:
            print(f"   üìä Massive dataset optimization for {len(X_train):,} samples")
            spacecraft_params.update({
                'n_estimators': 150,       # Reduce for speed
                'max_depth': 8,           # Reduce depth
                'learning_rate': 0.15,    # Slightly higher for faster convergence
                'subsample': 0.6,         # Smaller subsamples
                'colsample_bytree': 0.6,  # Fewer features per tree
                'n_jobs': 2               # Conservative for memory
            })
        
        # Create model based on classification mode
        if self.classification_mode == 'multilabel':
            xgb_model = MultiOutputClassifier(xgb.XGBClassifier(**spacecraft_params))
        else:
            xgb_model = xgb.XGBClassifier(**spacecraft_params)
        
        print(f"   üöÄ Training XGBoost with spacecraft parameters...")
        print(f"   Parameters: {len(X_train):,} samples, {spacecraft_params['n_estimators']} estimators")
        
        try:
            xgb_model.fit(X_train, y_train)
            print("   ‚úÖ XGBoost training completed successfully!")
        except Exception as e:
            print(f"   ‚ùå XGBoost training failed: {e}")
            return None
        
        training_time = time.time() - start_time
        
        # Make predictions and calculate metrics
        print(f"   üîÑ Generating spacecraft predictions...")
        y_pred = xgb_model.predict(X_test)
        
        # Calculate spacecraft-specific metrics
        metrics = self._calculate_spacecraft_metrics(y_test, y_pred, 'XGBoost')
        metrics['training_time'] = training_time
        metrics['model_params'] = spacecraft_params
        
        # Store model and results
        self.models['xgboost'] = xgb_model
        self.results['xgboost'] = metrics
        
        # Memory cleanup
        self._manage_memory("After XGBoost training")
        
        print(f"   ‚úÖ XGBoost completed in {training_time:.1f}s")
        print(f"   üìä Deployment Score: {metrics.get('deployment_score', 0):.1f}/100")
        self._print_spacecraft_metrics(metrics)
        
        return xgb_model
    
    def _train_spacecraft_neural_network(self, X_train, X_test, y_train, y_test, **kwargs):
        """Train Neural Network optimized for spacecraft bolt detection."""
        start_time = time.time()
        
        # Spacecraft-optimized Neural Network parameters
        spacecraft_params = {
            'hidden_layers': [256, 128, 64],  # Conservative architecture
            'dropout_rate': 0.3,              # Regularization
            'learning_rate': 0.001,           # Conservative learning rate
            'epochs': 100,                    # Max epochs with early stopping
            'batch_size': min(512, len(X_train) // 10),  # Adaptive batch size
            'patience': 15,                   # Early stopping patience
            'validation_split': 0.15          # Validation for early stopping
        }
        spacecraft_params.update(kwargs.get('neural_network', {}))
        
        # Adjust for massive datasets
        if len(X_train) > 100000:
            print(f"   üìä Massive dataset optimization for {len(X_train):,} samples")
            spacecraft_params.update({
                'hidden_layers': [128, 64, 32],    # Smaller network
                'batch_size': min(256, spacecraft_params['batch_size']),
                'validation_split': 0.1         # Smaller validation split
            })
        
        # Build spacecraft neural network
        print(f"   üß† Building spacecraft neural network...")
        
        try:
            model = Sequential()
            
            # Input layer
            model.add(Dense(spacecraft_params['hidden_layers'][0], 
                           activation='relu', input_shape=(X_train.shape[1],)))
            model.add(BatchNormalization())
            model.add(Dropout(spacecraft_params['dropout_rate']))
            
            # Hidden layers
            for units in spacecraft_params['hidden_layers'][1:]:
                model.add(Dense(units, activation='relu'))
                model.add(BatchNormalization())
                model.add(Dropout(spacecraft_params['dropout_rate']))
            
            # Output layer
            if self.classification_mode == 'multilabel':
                output_dim = y_train.shape[1]
                model.add(Dense(output_dim, activation='sigmoid'))
                model.compile(
                    optimizer=Adam(learning_rate=spacecraft_params['learning_rate']),
                    loss='binary_crossentropy',
                    metrics=['accuracy']
                )
            else:
                unique_classes = len(np.unique(y_train))
                model.add(Dense(unique_classes, activation='softmax'))
                
                # Convert to categorical
                y_train_cat = to_categorical(y_train - min(y_train))
                y_test_cat = to_categorical(y_test - min(y_test))
                y_train, y_test = y_train_cat, y_test_cat
                
                model.compile(
                    optimizer=Adam(learning_rate=spacecraft_params['learning_rate']),
                    loss='categorical_crossentropy',
                    metrics=['accuracy']
                )
            
            print(f"   Architecture: {spacecraft_params['hidden_layers']} ‚Üí {output_dim if self.classification_mode == 'multilabel' else unique_classes}")
            print(f"   Total parameters: {model.count_params():,}")
            
            # Callbacks for spacecraft safety
            callbacks = [
                EarlyStopping(
                    monitor='val_loss',
                    patience=spacecraft_params['patience'],
                    restore_best_weights=True,
                    verbose=0
                ),
                ReduceLROnPlateau(
                    monitor='val_loss',
                    factor=0.5,
                    patience=spacecraft_params['patience'] // 2,
                    min_lr=1e-6,
                    verbose=0
                )
            ]
            
            # Train the model
            print(f"   üß† Training neural network...")
            history = model.fit(
                X_train, y_train,
                validation_split=spacecraft_params['validation_split'],
                epochs=spacecraft_params['epochs'],
                batch_size=spacecraft_params['batch_size'],
                callbacks=callbacks,
                verbose=0
            )
            
            print("   ‚úÖ Neural Network training completed successfully!")
            
        except Exception as e:
            print(f"   ‚ùå Neural Network training failed: {e}")
            return None
        
        training_time = time.time() - start_time
        
        # Make predictions
        print(f"   üîÑ Generating spacecraft predictions...")
        if self.classification_mode == 'multilabel':
            y_pred_prob = model.predict(X_test, batch_size=spacecraft_params['batch_size'], verbose=0)
            y_pred = (y_pred_prob > 0.5).astype(int)
        else:
            y_pred_prob = model.predict(X_test, batch_size=spacecraft_params['batch_size'], verbose=0)
            y_pred = np.argmax(y_pred_prob, axis=1)
            y_test = np.argmax(y_test, axis=1)
            
            # Convert back to original class labels
            unique_classes = sorted(np.unique(self.y_single))
            y_pred = np.array([unique_classes[i] for i in y_pred])
            y_test = np.array([unique_classes[i] for i in y_test])
        
        # Calculate spacecraft-specific metrics
        metrics = self._calculate_spacecraft_metrics(y_test, y_pred, 'Neural Network')
        metrics['training_time'] = training_time
        metrics['training_epochs'] = len(history.history['loss'])
        metrics['model_params'] = spacecraft_params
        
        # Store model and results
        self.models['neural_network'] = model
        self.results['neural_network'] = metrics
        
        # Memory cleanup
        self._manage_memory("After Neural Network training")
        
        print(f"   ‚úÖ Neural Network completed in {training_time:.1f}s")
        print(f"   üìä Deployment Score: {metrics.get('deployment_score', 0):.1f}/100")
        print(f"   Training epochs: {metrics['training_epochs']}")
        self._print_spacecraft_metrics(metrics)
        
        return model
    
    def _train_spacecraft_ensemble(self, X_train, X_test, y_train, y_test, base_models):
        """Train ensemble optimized for spacecraft bolt detection."""
        start_time = time.time()
        
        print(f"   üéØ Creating spacecraft ensemble from {len(base_models)} models...")
        
        # Create ensemble from available models
        estimators = []
        model_weights = {}
        
        for model_name, model in base_models.items():
            if model and model_name in self.results:
                # Weight models by their deployment score
                deployment_score = self.results[model_name].get('deployment_score', 50)
                weight = max(0.1, deployment_score / 100)  # Minimum weight of 0.1
                
                estimators.append((model_name, model))
                model_weights[model_name] = weight
                print(f"     Adding {model_name}: weight {weight:.2f} (score: {deployment_score:.1f})")
        
        if len(estimators) < 2:
            print("   ‚ùå Need at least 2 models for spacecraft ensemble")
            return None
        
        try:
            # Create weighted voting ensemble for spacecraft safety
            ensemble = VotingClassifier(
                estimators=estimators,
                voting='soft',  # Use probability averaging for better spacecraft safety
                n_jobs=2       # Conservative for stability
            )
            
            print(f"   üéØ Training spacecraft ensemble...")
            ensemble.fit(X_train, y_train)
            print("   ‚úÖ Spacecraft ensemble training completed successfully!")
            
        except Exception as e:
            print(f"   ‚ùå Spacecraft ensemble training failed: {e}")
            return None
        
        training_time = time.time() - start_time
        
        # Make predictions
        print(f"   üîÑ Generating spacecraft ensemble predictions...")
        y_pred = ensemble.predict(X_test)
        
        # Calculate spacecraft-specific metrics
        metrics = self._calculate_spacecraft_metrics(y_test, y_pred, 'Spacecraft Ensemble')
        metrics['training_time'] = training_time
        metrics['base_models'] = list(model_weights.keys())
        metrics['model_weights'] = model_weights
        metrics['ensemble_size'] = len(estimators)
        
        # Store model and results
        self.models['ensemble'] = ensemble
        self.results['ensemble'] = metrics
        
        # Memory cleanup
        self._manage_memory("After Spacecraft Ensemble training")
        
        print(f"   ‚úÖ Spacecraft Ensemble completed in {training_time:.1f}s")
        print(f"   üìä Deployment Score: {metrics.get('deployment_score', 0):.1f}/100")
        print(f"   üéØ Base models: {metrics['base_models']}")
        self._print_spacecraft_metrics(metrics)
        
        return ensemble
    
    def _calculate_spacecraft_metrics(self, y_true, y_pred, model_name):
        """Calculate comprehensive metrics optimized for spacecraft deployment."""
        n_samples = len(y_true)
        
        if self.classification_mode == 'multilabel':
            n_labels = y_true.shape[1]
            
            # Exact Match Accuracy (all bolts correctly classified)
            exact_matches = np.all(y_true == y_pred, axis=1).sum()
            exact_match_accuracy = exact_matches / n_samples
            
            # Hamming Loss (average per-bolt error rate)
            hamming = hamming_loss(y_true, y_pred)
            
            # Jaccard Score (label overlap - critical for spacecraft)
            jaccard = jaccard_score(y_true, y_pred, average='samples', zero_division=0)
            
            # F1 Scores (precision-recall balance)
            f1_macro = f1_score(y_true, y_pred, average='macro', zero_division=0)
            f1_micro = f1_score(y_true, y_pred, average='micro', zero_division=0)
            f1_weighted = f1_score(y_true, y_pred, average='weighted', zero_division=0)
            
            # Precision and Recall
            precision_macro = precision_score(y_true, y_pred, average='macro', zero_division=0)
            recall_macro = recall_score(y_true, y_pred, average='macro', zero_division=0)
            
            # Spacecraft-specific metrics
            # False Negative Rate (missing loose bolts - critical for spacecraft safety)
            fn_rate = np.sum((y_true == 1) & (y_pred == 0)) / np.sum(y_true == 1) if np.sum(y_true == 1) > 0 else 0
            
            # False Positive Rate (false alarms - operational impact)
            fp_rate = np.sum((y_true == 0) & (y_pred == 1)) / np.sum(y_true == 0) if np.sum(y_true == 0) > 0 else 0
            
            base_metrics = {
                'exact_match_accuracy': exact_match_accuracy,
                'hamming_loss': hamming,
                'jaccard_score': jaccard,
                'f1_macro': f1_macro,
                'f1_micro': f1_micro,
                'f1_weighted': f1_weighted,
                'precision_macro': precision_macro,
                'recall_macro': recall_macro,
                'false_negative_rate': fn_rate,
                'false_positive_rate': fp_rate
            }
            
        else:
            # Single-label metrics
            accuracy = accuracy_score(y_true, y_pred)
            f1_macro = f1_score(y_true, y_pred, average='macro', zero_division=0)
            precision_macro = precision_score(y_true, y_pred, average='macro', zero_division=0)
            recall_macro = recall_score(y_true, y_pred, average='macro', zero_division=0)
            
            base_metrics = {
                'exact_match_accuracy': accuracy,
                'accuracy': accuracy,
                'f1_macro': f1_macro,
                'precision_macro': precision_macro,
                'recall_macro': recall_macro,
                'hamming_loss': 1 - accuracy,  # For consistency
                'jaccard_score': f1_macro,     # Approximation for single-label
                'false_negative_rate': 0,      # Would need per-class calculation
                'false_positive_rate': 0       # Would need per-class calculation
            }
        
        # üöÄ Spacecraft Deployment Score (Custom metric)
        deployment_score = self._calculate_spacecraft_deployment_score(base_metrics)
        
        # üéØ Spacecraft Safety Assessment
        safety_assessment = self._assess_spacecraft_safety(base_metrics)
        
        return {
            'model_name': model_name,
            'n_samples': n_samples,
            'n_labels': n_labels if self.classification_mode == 'multilabel' else 1,
            'deployment_score': deployment_score,
            'safety_assessment': safety_assessment,
            **base_metrics
        }
    
    def _calculate_spacecraft_deployment_score(self, metrics):
        """Calculate overall deployment readiness score for spacecraft (0-100)."""
        # Weighted scoring for spacecraft deployment
        weights = {
            'exact_match_accuracy': 0.3,    # 30% - Critical for spacecraft
            'jaccard_score': 0.25,          # 25% - Label overlap important
            'f1_macro': 0.2,                # 20% - Overall performance
            'low_hamming_loss': 0.15,       # 15% - Error minimization
            'safety_bonus': 0.1              # 10% - Safety considerations
        }
        
        # Base score components
        exact_match_component = metrics.get('exact_match_accuracy', 0) * weights['exact_match_accuracy']
        jaccard_component = metrics.get('jaccard_score', 0) * weights['jaccard_score']
        f1_component = metrics.get('f1_macro', 0) * weights['f1_macro']
        
        # Hamming loss component (inverted - lower is better)
        hamming_component = (1 - metrics.get('hamming_loss', 1)) * weights['low_hamming_loss']
        
        # Safety bonus for low false negatives (critical for spacecraft)
        fn_rate = metrics.get('false_negative_rate', 0)
        safety_bonus = max(0, (1 - fn_rate * 2)) * weights['safety_bonus']  # Penalty for high FN
        
        # Calculate final score
        deployment_score = (
            exact_match_component + 
            jaccard_component + 
            f1_component + 
            hamming_component + 
            safety_bonus
        ) * 100
        
        return min(100, max(0, deployment_score))
    
    def _assess_spacecraft_safety(self, metrics):
        """Assess safety readiness for spacecraft deployment."""
        exact_match = metrics.get('exact_match_accuracy', 0)
        jaccard = metrics.get('jaccard_score', 0)
        hamming = metrics.get('hamming_loss', 1)
        f1_macro = metrics.get('f1_macro', 0)
        fn_rate = metrics.get('false_negative_rate', 1)
        
        # Safety criteria for spacecraft
        safety_checks = {
            'exact_match_acceptable': exact_match >= self.deployment_thresholds['exact_match_min'],
            'jaccard_acceptable': jaccard >= self.deployment_thresholds['jaccard_min'],
            'hamming_acceptable': hamming <= self.deployment_thresholds['hamming_max'],
            'f1_acceptable': f1_macro >= self.deployment_thresholds['f1_macro_min'],
            'low_false_negatives': fn_rate <= 0.15  # <15% missed loose bolts
        }
        
        safety_score = sum(safety_checks.values()) / len(safety_checks)
        
        if safety_score >= 0.8:
            safety_level = "üöÄ SPACECRAFT DEPLOYMENT READY"
        elif safety_score >= 0.6:
            safety_level = "üîß CONDITIONAL DEPLOYMENT (with monitoring)"
        else:
            safety_level = "‚ö†Ô∏è  NOT READY (requires improvement)"
        
        return {
            'safety_level': safety_level,
            'safety_score': safety_score,
            'safety_checks': safety_checks,
            'passed_checks': sum(safety_checks.values()),
            'total_checks': len(safety_checks)
        }
    
    def _print_spacecraft_metrics(self, metrics):
        """Print spacecraft-specific metrics in a readable format."""
        if self.classification_mode == 'multilabel':
            print(f"     Exact Match: {metrics['exact_match_accuracy']:.1%}")
            print(f"     Jaccard Score: {metrics['jaccard_score']:.3f}")
            print(f"     Hamming Loss: {metrics['hamming_loss']:.3f}")
        else:
            print(f"     Accuracy: {metrics['exact_match_accuracy']:.1%}")
        
        print(f"     F1-Macro: {metrics['f1_macro']:.3f}")
        
        # Safety metrics
        safety = metrics['safety_assessment']
        print(f"     Safety Level: {safety['safety_level']}")
    
    def _spacecraft_deployment_assessment(self, training_results):
        """Comprehensive spacecraft deployment assessment."""
        print("\n" + "=" * 80)
        print("üöÄ SPACECRAFT DEPLOYMENT ASSESSMENT")
        print("=" * 80)
        
        if not training_results:
            print("‚ùå No models successfully trained")
            return
        
        # Find best model for spacecraft deployment
        best_model = None
        best_score = 0
        
        print("\nüìä MODEL PERFORMANCE SUMMARY:")
        print("-" * 50)
        
        for model_name, model in training_results.items():
            if model_name in self.results:
                metrics = self.results[model_name]
                deployment_score = metrics.get('deployment_score', 0)
                safety_level = metrics['safety_assessment']['safety_level']
                
                print(f"\n{model_name.upper()}:")
                print(f"  Deployment Score: {deployment_score:.1f}/100")
                print(f"  Safety Assessment: {safety_level}")
                print(f"  Training Time: {metrics.get('training_time', 0):.1f}s")
                
                if deployment_score > best_score:
                    best_score = deployment_score
                    best_model = model_name
        
        # Overall recommendation
        print("\n" + "=" * 50)
        print("üéØ SPACECRAFT DEPLOYMENT RECOMMENDATION:")
        print("=" * 50)
        
        if best_model:
            print(f"üèÜ RECOMMENDED MODEL: {best_model.upper()}")
            print(f"üìä DEPLOYMENT SCORE: {best_score:.1f}/100")
            
            best_metrics = self.results[best_model]
            safety_assessment = best_metrics['safety_assessment']
            
            print(f"üõ°Ô∏è  SAFETY ASSESSMENT: {safety_assessment['safety_level']}")
            print(f"‚úÖ SAFETY CHECKS PASSED: {safety_assessment['passed_checks']}/{safety_assessment['total_checks']}")
            
            if best_score >= self.deployment_thresholds['deployment_score_min']:
                print("\nüöÄ STATUS: READY FOR SPACECRAFT DEPLOYMENT")
                print("   ‚úÖ Meets all spacecraft safety requirements")
                print("   ‚úÖ Suitable for critical bolt monitoring systems")
                print("   ‚úÖ Recommended for integration with spacecraft health monitoring")
            else:
                print("\nüîß STATUS: REQUIRES OPTIMIZATION FOR SPACECRAFT DEPLOYMENT")
                print("   ‚ö†Ô∏è  Performance below spacecraft safety thresholds")
                print("   üí° Recommendations:")
                print("      - Consider ensemble methods")
                print("      - Increase dataset size")
                print("      - Optimize hyperparameters")
                print("      - Apply advanced feature engineering")
        else:
            print("‚ùå NO SUITABLE MODEL FOR SPACECRAFT DEPLOYMENT")
            print("   All models failed to meet minimum requirements")
        
        print("\n" + "=" * 80)
    
    def get_spacecraft_model_comparison(self):
        """Get detailed comparison of all trained models for spacecraft applications."""
        if not self.results:
            return None
        
        comparison_data = []
        
        for model_name, metrics in self.results.items():
            # Format metrics for display
            row = {
                'Model': model_name.replace('_', ' ').title(),
                'Deployment_Score': f"{metrics.get('deployment_score', 0):.1f}/100",
                'Safety_Level': metrics['safety_assessment']['safety_level'].split()[-1],  # Extract status
                'Exact_Match': f"{metrics.get('exact_match_accuracy', 0):.1%}",
                'Jaccard_Score': f"{metrics.get('jaccard_score', 0):.3f}",
                'Hamming_Loss': f"{metrics.get('hamming_loss', 0):.3f}",
                'F1_Macro': f"{metrics.get('f1_macro', 0):.3f}",
                'Training_Time': f"{metrics.get('training_time', 0):.1f}s",
                'Safety_Checks': f"{metrics['safety_assessment']['passed_checks']}/{metrics['safety_assessment']['total_checks']}"
            }
            
            # Add model-specific information
            if 'base_models' in metrics:  # Ensemble
                row['Base_Models'] = '+'.join(metrics['base_models'])
            elif 'oob_score' in metrics and metrics['oob_score']:  # Random Forest
                row['OOB_Score'] = f"{metrics['oob_score']:.3f}"
            elif 'training_epochs' in metrics:  # Neural Network
                row['Epochs'] = str(metrics['training_epochs'])
            
            comparison_data.append(row)
        
        # Sort by deployment score
        comparison_df = pd.DataFrame(comparison_data)
        if len(comparison_df) > 0:
            comparison_df['Score_Numeric'] = comparison_df['Deployment_Score'].str.replace('/100', '').astype(float)
            comparison_df = comparison_df.sort_values('Score_Numeric', ascending=False)
            comparison_df = comparison_df.drop('Score_Numeric', axis=1)
        
        return comparison_df
    
    def predict_spacecraft_bolt_condition(self, X_new, model_name='best', confidence_threshold=0.5):
        """
        üéØ Predict spacecraft bolt condition with enhanced safety features.
        """
        if not self.is_trained:
            return {'error': 'No models trained yet'}
        
        # Select best model if requested
        if model_name == 'best':
            best_score = 0
            for name, metrics in self.results.items():
                score = metrics.get('deployment_score', 0)
                if score > best_score:
                    best_score = score
                    model_name = name
        
        if model_name not in self.models:
            return {'error': f'Model {model_name} not available'}
        
        model = self.models[model_name]
        
        try:
            # Ensure proper input format
            if X_new.ndim == 1:
                X_new = X_new.reshape(1, -1)
            
            # Scale features using fitted scaler
            X_scaled = self.scaler.transform(X_new)
            
            # Get predictions
            if self.classification_mode == 'multilabel':
                # Multi-label prediction
                if hasattr(model, 'predict_proba'):
                    try:
                        pred_proba = model.predict_proba(X_scaled)
                        if isinstance(pred_proba, list):  # MultiOutputClassifier
                            confidences = np.array([proba[0][1] for proba in pred_proba])
                        else:
                            confidences = pred_proba[0]
                    except:
                        confidences = np.full(len(self.cbush_numbers), 0.5)
                else:
                    confidences = np.full(len(self.cbush_numbers), 0.5)
                
                # Apply threshold
                predictions = (confidences > confidence_threshold).astype(int)
                
                # Identify loose bolts
                loose_cbushes = [self.cbush_numbers[i] for i in range(len(predictions)) if predictions[i] == 1]
                
                # Spacecraft-specific assessment
                risk_level = self._assess_spacecraft_risk(loose_cbushes, confidences)
                
                return {
                    'model_used': model_name,
                    'classification_mode': 'multilabel',
                    'loose_cbushes': loose_cbushes,
                    'loose_count': len(loose_cbushes),
                    'cbush_probabilities': dict(zip(self.cbush_numbers[:len(confidences)], confidences)),
                    'prediction_vector': predictions.tolist(),
                    'confidence_vector': confidences.tolist(),
                    'risk_level': risk_level,
                    'spacecraft_ready': risk_level['deployment_safe'],
                    'threshold_used': confidence_threshold
                }
            
            else:
                # Single-label prediction
                predictions = model.predict(X_scaled)
                if hasattr(model, 'predict_proba'):
                    try:
                        confidences = model.predict_proba(X_scaled)
                        max_confidence = np.max(confidences[0])
                    except:
                        max_confidence = 0.5
                else:
                    max_confidence = 0.5
                
                return {
                    'model_used': model_name,
                    'classification_mode': 'single',
                    'predicted_cbush': predictions[0],
                    'confidence': max_confidence,
                    'spacecraft_ready': max_confidence > 0.7
                }
        
        except Exception as e:
            return {'error': f'Prediction failed: {str(e)}'}
    
    def _assess_spacecraft_risk(self, loose_cbushes, confidences):
        """Assess spacecraft risk level based on bolt predictions."""
        num_loose = len(loose_cbushes)
        avg_confidence = np.mean(confidences) if len(confidences) > 0 else 0
        max_confidence = np.max(confidences) if len(confidences) > 0 else 0
        
        # Risk assessment logic for spacecraft
        if num_loose == 0:
            risk_level = "üü¢ LOW"
            deployment_safe = True
            recommendation = "All bolts secure - normal operations"
        elif num_loose == 1 and max_confidence < 0.8:
            risk_level = "üü° MEDIUM"
            deployment_safe = True
            recommendation = "Single bolt concern - monitor closely"
        elif num_loose <= 2 and avg_confidence < 0.9:
            risk_level = "üü° MEDIUM-HIGH"
            deployment_safe = False
            recommendation = "Multiple bolts loose - inspection required"
        else:
            risk_level = "üî¥ HIGH"
            deployment_safe = False
            recommendation = "Critical bolt failure - immediate action required"
        
        return {
            'level': risk_level,
            'deployment_safe': deployment_safe,
            'recommendation': recommendation,
            'num_loose_bolts': num_loose,
            'avg_confidence': avg_confidence,
            'max_confidence': max_confidence
        }
    
    # Legacy compatibility methods
    def load_data(self, master_df, chunk_size=None):
        """Legacy method for backward compatibility."""
        return self.load_data(master_df, chunk_size)
    
    def prepare_targets(self, classification_type='auto'):
        """Legacy method for backward compatibility."""
        return self.prepare_targets(classification_type)
    
    def train_ml_trinity(self, master_df):
        """Public interface for training the ML Trinity."""
        # Load and prepare data
        self.load_data(master_df)
        self.prepare_targets('auto')
        
        # Train all models
        return self.train_spacecraft_ml_trinity()
    
    def get_model_comparison(self):
        """Public interface for model comparison."""
        return self.get_spacecraft_model_comparison()
    
    def predict_bolt_condition(self, X_new, model_name='best'):
        """Public interface for bolt condition prediction."""
        return self.predict_spacecraft_bolt_condition(X_new, model_name)
    
    # Utility methods
    def _manage_memory(self, context=""):
        """Enhanced memory management for massive datasets."""
        if not self.enable_memory_management:
            return
        
        try:
            process = psutil.Process()
            memory_mb = process.memory_info().rss / 1024 / 1024
            memory_gb = memory_mb / 1024
            
            if memory_gb > self.max_memory_gb * 0.8:
                print(f"   ‚ö†Ô∏è  High memory usage ({memory_gb:.1f}GB) at {context}, cleaning up...")
                
                # Force garbage collection
                collected = gc.collect()
                
                # TensorFlow specific cleanup
                if TENSORFLOW_AVAILABLE:
                    try:
                        tf.keras.backend.clear_session()
                    except:
                        pass
                
                memory_mb_after = process.memory_info().rss / 1024 / 1024
                memory_gb_after = memory_mb_after / 1024
                
                saved_mb = memory_mb - memory_mb_after
                print(f"     Memory cleanup: {saved_mb:.1f}MB freed, {collected} objects collected")
                print(f"     Memory after cleanup: {memory_gb_after:.1f}GB")
                
        except Exception as e:
            print(f"   ‚ö†Ô∏è  Memory management warning: {e}")
    
    def _check_memory_usage(self, context=""):
        """Check and report current memory usage."""
        try:
            process = psutil.Process()
            memory_mb = process.memory_info().rss / 1024 / 1024
            memory_gb = memory_mb / 1024
            
            print(f"   Memory usage {context}: {memory_gb:.1f}GB")
            
            if memory_gb > self.max_memory_gb * 0.9:
                print(f"   ‚ö†Ô∏è  Warning: Memory usage approaching limit ({self.max_memory_gb}GB)")
                
        except Exception as e:
            print(f"   ‚ö†Ô∏è  Memory check warning: {e}")
    
    def save_spacecraft_model(self, model_name, filepath):
        """Save trained model with spacecraft-specific metadata."""
        if model_name not in self.models:
            print(f"‚ùå Model {model_name} not found")
            return False
        
        try:
            model = self.models[model_name]
            
            if model_name == 'neural_network':
                # Save Keras model
                model.save(filepath)
                # Save spacecraft metadata
                metadata = {
                    'scaler': self.scaler,
                    'feature_names': self.feature_names,
                    'classification_mode': self.classification_mode,
                    'cbush_numbers': self.cbush_numbers,
                    'deployment_thresholds': self.deployment_thresholds,
                    'spacecraft_metrics': self.results.get(model_name, {}),
                    'version': 'spacecraft_v1.0'
                }
                
                metadata_path = filepath.replace('.h5', '_spacecraft_metadata.pkl')
                joblib.dump(metadata, metadata_path)
                
            else:
                # Save sklearn model with spacecraft metadata
                model_data = {
                    'model': model,
                    'scaler': self.scaler,
                    'feature_names': self.feature_names,
                    'classification_mode': self.classification_mode,
                    'cbush_numbers': self.cbush_numbers,
                    'deployment_thresholds': self.deployment_thresholds,
                    'spacecraft_metrics': self.results.get(model_name, {}),
                    'version': 'spacecraft_v1.0'
                }
                joblib.dump(model_data, filepath)
            
            print(f"‚úÖ Spacecraft model {model_name} saved to {filepath}")
            return True
            
        except Exception as e:
            print(f"‚ùå Error saving spacecraft model: {e}")
            return False


def main():
    """Example usage of Enhanced Spacecraft ML Pipeline."""
    print("üöÄ Enhanced Spacecraft Multi-CBUSH ML Pipeline v2.0 Ready!")
    print("Features:")
    print("  ‚úÖ ML Trinity: Random Forest + XGBoost + Ensemble")
    print("  ‚úÖ Spacecraft deployment readiness assessment")
    print("  ‚úÖ Enhanced safety metrics and risk assessment")
    print("  ‚úÖ Memory optimization for massive datasets (11K-111K+ designs)")
    print("  ‚úÖ Advanced multi-label classification for bolt detection")
    print("  ‚úÖ Production-ready for spacecraft health monitoring systems")


if __name__ == "__main__":
    main()
