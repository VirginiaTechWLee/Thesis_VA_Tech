import tkinter as tk
from tkinter import ttk, filedialog, messagebox, scrolledtext
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
from matplotlib.backends.backend_tkagg import FigureCanvasTkAgg
import seaborn as sns
import threading
import os
from pathlib import Path
import time

# Import our custom modules
from multi_cbush_processor import MultiCBUSHProcessor
from multi_cbush_ml_pipeline import MultiCBUSHMLPipeline
from comprehensive_scoring_system import ComprehensiveMultiLabelScoring

class EnhancedBoltDetectionGUI:
    """
    Complete GUI for Multi-CBUSH Bolt Anomaly Detection System.
    Supports combined dataset (896 designs), multi-label classification, and prediction.
    """
    
    def __init__(self, root):
        """Initialize the enhanced GUI application."""
        self.root = root
        self.root.title("Multi-CBUSH Bolt Anomaly Detection System v2.0")
        self.root.geometry("1600x1000")
        self.root.configure(bg='#f0f0f0')
        
        # Initialize backend components
        self.processor = MultiCBUSHProcessor()
        self.ml_pipeline = MultiCBUSHMLPipeline()
        self.scoring_system = ComprehensiveMultiLabelScoring()
        self.current_data = None
        self.comprehensive_scores = {}
        
        # Create GUI components
        self.create_widgets()
        
        # Status tracking
        self.processing_thread = None
        self.training_thread = None
    
    def create_widgets(self):
        """Create all GUI widgets."""
        # Create notebook for tabs
        self.notebook = ttk.Notebook(self.root)
        self.notebook.pack(fill='both', expand=True, padx=10, pady=10)
        
        # Create tabs
        self.create_setup_tab()
        self.create_processing_tab()
        self.create_matrix_tab()
        self.create_ml_tab()
        self.create_scoring_tab()
        self.create_prediction_tab()
        self.create_spatial_tab()
        self.create_results_tab()
        self.create_export_tab()
    
    def create_setup_tab(self):
        """Create setup and configuration tab."""
        setup_frame = ttk.Frame(self.notebook)
        self.notebook.add(setup_frame, text="Setup")
        
        # Title
        title_label = tk.Label(setup_frame, text="Multi-CBUSH Bolt Detection System v2.0", 
                              font=('Arial', 18, 'bold'), bg='#f0f0f0', fg='#2c3e50')
        title_label.pack(pady=15)
        
        subtitle_label = tk.Label(setup_frame, text="Combined Dataset | Multi-Label Classification | Spacecraft Ready", 
                                 font=('Arial', 12), bg='#f0f0f0', fg='#7f8c8d')
        subtitle_label.pack(pady=5)
        
        # Study folder configuration
        config_frame = ttk.LabelFrame(setup_frame, text="Study Folder Configuration")
        config_frame.pack(fill='x', padx=20, pady=15)
        
        # Study folder paths
        self.study_paths = {}
        self.study_path_vars = {}
        
        study_folders = ['Study1', 'Study2', 'Study3']
        study_descriptions = [
            'Single-CBUSH Studies (576 designs)',
            'Adjacent Pair Studies (128 designs)', 
            'Multi-Bolt Studies (192 designs)'
        ]
        
        for i, (folder, description) in enumerate(zip(study_folders, study_descriptions)):
            # Folder label
            folder_frame = tk.Frame(config_frame)
            folder_frame.pack(fill='x', padx=10, pady=8)
            
            tk.Label(folder_frame, text=f"{folder} - {description}:", 
                    font=('Arial', 10, 'bold')).pack(anchor='w')
            
            # Path input
            path_input_frame = tk.Frame(folder_frame)
            path_input_frame.pack(fill='x', pady=5)
            
            self.study_path_vars[folder] = tk.StringVar()
            path_entry = tk.Entry(path_input_frame, textvariable=self.study_path_vars[folder], 
                                 width=100, font=('Arial', 9))
            path_entry.pack(side='left', fill='x', expand=True)
            
            tk.Button(path_input_frame, text="Browse", 
                     command=lambda f=folder: self.browse_study_path(f)).pack(side='right', padx=(5,0))
        
        # Initialize button
        init_frame = tk.Frame(config_frame)
        init_frame.pack(fill='x', padx=10, pady=15)
        
        tk.Button(init_frame, text="Initialize Processor", command=self.initialize_processor,
                 bg='#27ae60', fg='white', font=('Arial', 12, 'bold'), 
                 height=2, width=20).pack()
        
        # System status
        self.status_frame = ttk.LabelFrame(setup_frame, text="System Status & Log")
        self.status_frame.pack(fill='both', expand=True, padx=20, pady=15)
        
        self.status_text = scrolledtext.ScrolledText(self.status_frame, height=20, width=100,
                                                    font=('Consolas', 9))
        self.status_text.pack(fill='both', expand=True, padx=10, pady=10)
        
        # Initial status message
        self.log_message("üöÄ Welcome to Multi-CBUSH Bolt Detection System v2.0")
        self.log_message("üìä Supports: Combined Dataset (896 designs) | Multi-Label Classification")
        self.log_message("üîß Please configure study folder paths and initialize processor to begin.")
    
    def create_processing_tab(self):
        """Create enhanced data processing tab."""
        processing_frame = ttk.Frame(self.notebook)
        self.notebook.add(processing_frame, text="Data Processing")
        
        # Study selection with enhanced layout
        selection_frame = ttk.LabelFrame(processing_frame, text="Study Selection & Processing")
        selection_frame.pack(fill='x', padx=20, pady=15)
        
        tk.Label(selection_frame, text="Select Studies to Process:", 
                font=('Arial', 12, 'bold')).pack(anchor='w', padx=10, pady=10)
        
        self.study_vars = {}
        
        # Create study selection in organized columns
        studies_grid = tk.Frame(selection_frame)
        studies_grid.pack(fill='x', padx=10, pady=10)
        
        # Single-CBUSH studies
        single_frame = ttk.LabelFrame(studies_grid, text="Study 1: Single-CBUSH (576 designs)")
        single_frame.grid(row=0, column=0, sticky='ew', padx=5, pady=5)
        
        single_studies = ['S1A', 'S1B', 'S1C', 'S1D', 'S1E', 'S1F', 'S1G', 'S1H', 'S1I']
        single_names = ['CB2', 'CB3', 'CB4', 'CB5', 'CB6', 'CB7', 'CB8', 'CB9', 'CB10']
        
        for i, (study_id, name) in enumerate(zip(single_studies, single_names)):
            self.study_vars[study_id] = tk.BooleanVar()
            cb = tk.Checkbutton(single_frame, text=f"{study_id} ({name})", 
                               variable=self.study_vars[study_id])
            cb.grid(row=i//3, column=i%3, sticky='w', padx=5, pady=2)
        
        # Adjacent pair studies
        adjacent_frame = ttk.LabelFrame(studies_grid, text="Study 2: Adjacent Pairs (128 designs)")
        adjacent_frame.grid(row=0, column=1, sticky='ew', padx=5, pady=5)
        
        adjacent_studies = ['S2A', 'S2B', 'S2C', 'S2D', 'S2E', 'S2F', 'S2G', 'S2H']
        adjacent_names = ['CB2-3', 'CB3-4', 'CB4-5', 'CB5-6', 'CB6-7', 'CB7-8', 'CB8-9', 'CB9-10']
        
        for i, (study_id, name) in enumerate(zip(adjacent_studies, adjacent_names)):
            self.study_vars[study_id] = tk.BooleanVar()
            cb = tk.Checkbutton(adjacent_frame, text=f"{study_id} ({name})", 
                               variable=self.study_vars[study_id])
            cb.grid(row=i//2, column=i%2, sticky='w', padx=5, pady=2)
        
        # Multi-bolt studies
        multibolt_frame = ttk.LabelFrame(studies_grid, text="Study 3: Multi-Bolt (192 designs)")
        multibolt_frame.grid(row=0, column=2, sticky='ew', padx=5, pady=5)
        
        multibolt_studies = ['S3A', 'S3B', 'S3C']
        multibolt_names = ['CB2-5-8', 'CB3-6-9', 'CB4-7-10']
        
        for i, (study_id, name) in enumerate(zip(multibolt_studies, multibolt_names)):
            self.study_vars[study_id] = tk.BooleanVar()
            cb = tk.Checkbutton(multibolt_frame, text=f"{study_id} ({name})", 
                               variable=self.study_vars[study_id])
            cb.grid(row=i, column=0, sticky='w', padx=5, pady=2)
        
        # Configure grid weights
        studies_grid.grid_columnconfigure(0, weight=1)
        studies_grid.grid_columnconfigure(1, weight=1)
        studies_grid.grid_columnconfigure(2, weight=1)
        
        # Quick selection buttons
        button_frame = tk.Frame(selection_frame)
        button_frame.pack(fill='x', padx=10, pady=15)
        
        buttons = [
            ("Select All Single", lambda: self.select_study_type('single'), '#3498db'),
            ("Select All Adjacent", lambda: self.select_study_type('adjacent'), '#9b59b6'),
            ("Select All Multi-Bolt", lambda: self.select_study_type('multibolt'), '#e74c3c'),
            ("Select All Studies", lambda: self.select_all_studies(), '#27ae60'),
            ("Clear All", self.clear_all_studies, '#95a5a6')
        ]
        
        for text, command, color in buttons:
            tk.Button(button_frame, text=text, command=command, bg=color, fg='white',
                     font=('Arial', 10, 'bold')).pack(side='left', padx=5)
        
        # Processing controls
        control_frame = ttk.LabelFrame(processing_frame, text="Processing Controls")
        control_frame.pack(fill='x', padx=20, pady=15)
        
        tk.Button(control_frame, text="üîÑ Process Selected Studies", 
                 command=self.process_selected_studies,
                 bg='#2980b9', fg='white', font=('Arial', 14, 'bold'), 
                 height=2, width=25).pack(pady=15)
        
        # Progress tracking
        progress_frame = tk.Frame(control_frame)
        progress_frame.pack(fill='x', padx=10, pady=10)
        
        tk.Label(progress_frame, text="Processing Progress:", font=('Arial', 10)).pack(anchor='w')
        
        self.progress_var = tk.DoubleVar()
        self.progress_bar = ttk.Progressbar(progress_frame, variable=self.progress_var, 
                                          maximum=100, length=500)
        self.progress_bar.pack(pady=5)
        
        self.progress_label = tk.Label(progress_frame, text="Ready to process", 
                                      font=('Arial', 9), fg='#7f8c8d')
        self.progress_label.pack()
    
    def create_matrix_tab(self):
        """Create enhanced matrix creation tab."""
        matrix_frame = ttk.Frame(self.notebook)
        self.notebook.add(matrix_frame, text="Matrix Creation")
        
        # Processed studies overview
        overview_frame = ttk.LabelFrame(matrix_frame, text="Processed Studies Overview")
        overview_frame.pack(fill='both', expand=True, padx=20, pady=15)
        
        # Create enhanced tree view
        columns = ('Study ID', 'Type', 'CBUSHes', 'Designs', 'Status', 'Folder')
        self.studies_tree = ttk.Treeview(overview_frame, columns=columns, show='headings', height=12)
        
        # Configure columns
        column_widths = {'Study ID': 80, 'Type': 100, 'CBUSHes': 120, 'Designs': 80, 'Status': 120, 'Folder': 150}
        for col in columns:
            self.studies_tree.heading(col, text=col)
            self.studies_tree.column(col, width=column_widths.get(col, 100))
        
        # Add scrollbars
        tree_frame = tk.Frame(overview_frame)
        tree_frame.pack(fill='both', expand=True, padx=10, pady=10)
        
        scrollbar_v = ttk.Scrollbar(tree_frame, orient='vertical', command=self.studies_tree.yview)
        scrollbar_h = ttk.Scrollbar(tree_frame, orient='horizontal', command=self.studies_tree.xview)
        self.studies_tree.configure(yscrollcommand=scrollbar_v.set, xscrollcommand=scrollbar_h.set)
        
        self.studies_tree.pack(side='left', fill='both', expand=True)
        scrollbar_v.pack(side='right', fill='y')
        scrollbar_h.pack(side='bottom', fill='x')
        
        # Matrix creation controls
        matrix_control_frame = ttk.LabelFrame(matrix_frame, text="Master Matrix Creation")
        matrix_control_frame.pack(fill='x', padx=20, pady=15)
        
        # Matrix type selection with enhanced options
        tk.Label(matrix_control_frame, text="Select Matrix Type:", 
                font=('Arial', 12, 'bold')).pack(anchor='w', padx=10, pady=10)
        
        self.matrix_type = tk.StringVar(value="combined")
        matrix_options = [
            ("üéØ Combined Matrix (ALL Studies - 896 designs)", "combined", "The complete dataset for multi-label classification"),
            ("üìä Single-CBUSH Only (576 designs)", "single", "Traditional single-bolt classification"),
            ("üîó Adjacent Pairs Only (128 designs)", "adjacent", "Two-bolt scenario analysis"),
            ("üåü Multi-Bolt Only (192 designs)", "multibolt", "Complex multi-bolt scenarios")
        ]
        
        for text, value, description in matrix_options:
            frame = tk.Frame(matrix_control_frame)
            frame.pack(anchor='w', padx=20, pady=5)
            
            tk.Radiobutton(frame, text=text, variable=self.matrix_type, value=value,
                          font=('Arial', 11, 'bold')).pack(anchor='w')
            tk.Label(frame, text=f"   {description}", font=('Arial', 9), 
                    fg='#7f8c8d').pack(anchor='w')
        
        # Matrix creation button
        create_frame = tk.Frame(matrix_control_frame)
        create_frame.pack(fill='x', padx=10, pady=20)
        
        tk.Button(create_frame, text="üî® Create Master Matrix", 
                 command=self.create_master_matrix,
                 bg='#e67e22', fg='white', font=('Arial', 14, 'bold'),
                 height=2, width=20).pack(side='left')
        
        tk.Button(create_frame, text="üíæ Save Matrix as CSV", 
                 command=self.save_matrix_csv,
                 bg='#16a085', fg='white', font=('Arial', 12, 'bold'),
                 height=2, width=18).pack(side='left', padx=10)
        
        # Matrix information display
        self.matrix_info_text = scrolledtext.ScrolledText(matrix_control_frame, height=8, width=80,
                                                         font=('Consolas', 9))
        self.matrix_info_text.pack(fill='x', padx=10, pady=10)
        self.matrix_info_text.insert('1.0', "No matrix created yet. Select studies and create matrix.")
    
    def create_ml_tab(self):
        """Create enhanced machine learning tab."""
        ml_frame = ttk.Frame(self.notebook)
        self.notebook.add(ml_frame, text="Machine Learning")
        
        # ML configuration
        config_frame = ttk.LabelFrame(ml_frame, text="ML Configuration")
        config_frame.pack(fill='x', padx=20, pady=15)
        
        # Strategy selection
        strategy_frame = tk.Frame(config_frame)
        strategy_frame.pack(fill='x', padx=10, pady=10)
        
        tk.Label(strategy_frame, text="ML Strategy:", font=('Arial', 12, 'bold')).pack(anchor='w')
        
        # Get available strategies from ML pipeline
        available_strategies = list(self.ml_pipeline.ml_strategies.items())
        
        self.ml_strategy = tk.StringVar()
        if available_strategies:
            self.ml_strategy.set(available_strategies[0][0])
        
        strategy_grid = tk.Frame(strategy_frame)
        strategy_grid.pack(anchor='w', padx=20, pady=10)
        
        for i, (value, text) in enumerate(available_strategies):
            tk.Radiobutton(strategy_grid, text=text, variable=self.ml_strategy, value=value,
                          font=('Arial', 11)).grid(row=i//2, column=i%2, sticky='w', padx=10, pady=3)
        
        # Show unavailable strategies
        unavailable_strategies = []
        if 'neural_network' not in dict(available_strategies):
            unavailable_strategies.append("Neural Network (TensorFlow required)")
        if 'xgboost' not in dict(available_strategies):
            unavailable_strategies.append("XGBoost (XGBoost required)")
        
        if unavailable_strategies:
            tk.Label(strategy_frame, text="Unavailable (install dependencies):", 
                    font=('Arial', 10, 'bold'), fg='#e74c3c').pack(anchor='w', padx=20, pady=(10,5))
            for strategy in unavailable_strategies:
                tk.Label(strategy_frame, text=f"‚ùå {strategy}", 
                        font=('Arial', 9), fg='#7f8c8d').pack(anchor='w', padx=30)
        
        # Classification type
        class_frame = tk.Frame(config_frame)
        class_frame.pack(fill='x', padx=10, pady=10)
        
        tk.Label(class_frame, text="Classification Type:", font=('Arial', 12, 'bold')).pack(anchor='w')
        
        self.classification_type = tk.StringVar(value="auto")
        class_types = [
            ("ü§ñ Auto-detect (Recommended)", "auto", "Automatically choose best approach"),
            ("üè∑Ô∏è Multi-Label Classification", "multilabel", "Predict multiple loose CBUSHes"),
            ("üéØ Single-CBUSH (Legacy)", "single", "Traditional single-bolt classification")
        ]
        
        for text, value, description in class_types:
            frame = tk.Frame(class_frame)
            frame.pack(anchor='w', padx=20, pady=3)
            
            tk.Radiobutton(frame, text=text, variable=self.classification_type, value=value,
                          font=('Arial', 11)).pack(anchor='w')
            tk.Label(frame, text=f"   {description}", font=('Arial', 9), 
                    fg='#7f8c8d').pack(anchor='w')
        
        # Training controls
        training_frame = ttk.LabelFrame(ml_frame, text="Model Training")
        training_frame.pack(fill='x', padx=20, pady=15)
        
        train_button_frame = tk.Frame(training_frame)
        train_button_frame.pack(pady=15)
        
        tk.Button(train_button_frame, text="üß† Train Selected Model", 
                 command=self.train_model,
                 bg='#27ae60', fg='white', font=('Arial', 14, 'bold'),
                 height=2, width=20).pack()
        
        # Training progress
        progress_frame = tk.Frame(training_frame)
        progress_frame.pack(fill='x', padx=10, pady=10)
        
        tk.Label(progress_frame, text="Training Progress:", font=('Arial', 10)).pack(anchor='w')
        
        self.training_progress_var = tk.DoubleVar()
        self.training_progress_bar = ttk.Progressbar(progress_frame, variable=self.training_progress_var, 
                                                    maximum=100, length=500, mode='indeterminate')
        self.training_progress_bar.pack(pady=5)
        
        # Model status
        self.model_status_var = tk.StringVar(value="No model trained yet")
        status_label = tk.Label(progress_frame, textvariable=self.model_status_var, 
                               font=('Arial', 11, 'bold'), fg='#2c3e50')
        status_label.pack(pady=5)
    
    def create_scoring_tab(self):
        """Create comprehensive model scoring and metrics tab."""
        scoring_frame = ttk.Frame(self.notebook)
        self.notebook.add(scoring_frame, text="üìä Model Scoring")
        
        # Title
        title_label = tk.Label(scoring_frame, text="Comprehensive Model Performance Analysis", 
                              font=('Arial', 16, 'bold'), fg='#2c3e50')
        title_label.pack(pady=15)
        
        # Create scoring notebook with sub-tabs
        scoring_notebook = ttk.Notebook(scoring_frame)
        scoring_notebook.pack(fill='both', expand=True, padx=20, pady=15)
        
        # Sub-tab 1: Model Comparison
        comparison_frame = ttk.Frame(scoring_notebook)
        scoring_notebook.add(comparison_frame, text="Model Comparison")
        
        # Refresh scores button
        refresh_frame = tk.Frame(comparison_frame)
        refresh_frame.pack(fill='x', padx=10, pady=10)
        
        tk.Button(refresh_frame, text="üîÑ Calculate Comprehensive Scores", 
                 command=self.calculate_comprehensive_scores,
                 bg='#3498db', fg='white', font=('Arial', 12, 'bold')).pack(side='left')
        
        tk.Button(refresh_frame, text="üìä Generate Score Visualizations", 
                 command=self.generate_score_visualizations,
                 bg='#9b59b6', fg='white', font=('Arial', 12, 'bold')).pack(side='left', padx=10)
        
        # Model comparison table
        table_frame = ttk.LabelFrame(comparison_frame, text="Model Performance Comparison")
        table_frame.pack(fill='both', expand=True, padx=10, pady=10)
        
        # Create tree view for comparison table
        comparison_columns = ('Model', 'Exact Match', 'Jaccard Score', 'Hamming Loss', 
                            'F1 (Macro)', 'Precision (Macro)', 'Recall (Macro)', 'ROC AUC', 'Deployment Ready')
        self.comparison_tree = ttk.Treeview(table_frame, columns=comparison_columns, show='headings', height=8)
        
        for col in comparison_columns:
            self.comparison_tree.heading(col, text=col)
            self.comparison_tree.column(col, width=110)
        
        # Add scrollbars to comparison table
        comparison_scroll_v = ttk.Scrollbar(table_frame, orient='vertical', command=self.comparison_tree.yview)
        comparison_scroll_h = ttk.Scrollbar(table_frame, orient='horizontal', command=self.comparison_tree.xview)
        self.comparison_tree.configure(yscrollcommand=comparison_scroll_v.set, xscrollcommand=comparison_scroll_h.set)
        
        self.comparison_tree.pack(side='left', fill='both', expand=True, padx=10, pady=10)
        comparison_scroll_v.pack(side='right', fill='y')
        comparison_scroll_h.pack(side='bottom', fill='x')
        
        # Sub-tab 2: Detailed Metrics
        detailed_frame = ttk.Frame(scoring_notebook)
        scoring_notebook.add(detailed_frame, text="Detailed Metrics")
        
        # Model selector for detailed view
        model_selector_frame = tk.Frame(detailed_frame)
        model_selector_frame.pack(fill='x', padx=10, pady=10)
        
        tk.Label(model_selector_frame, text="Select Model for Detailed Analysis:", 
                font=('Arial', 12, 'bold')).pack(anchor='w')
        
        self.selected_model_for_details = tk.StringVar()
        self.model_selector = ttk.Combobox(model_selector_frame, textvariable=self.selected_model_for_details,
                                          state='readonly', font=('Arial', 11))
        self.model_selector.pack(anchor='w', pady=5)
        self.model_selector.bind('<<ComboboxSelected>>', self.update_detailed_metrics)
        
        # Detailed metrics display
        self.detailed_metrics_text = scrolledtext.ScrolledText(detailed_frame, height=25, width=100,
                                                              font=('Consolas', 9))
        self.detailed_metrics_text.pack(fill='both', expand=True, padx=10, pady=10)
        
        # Sub-tab 3: Per-CBUSH Analysis
        per_cbush_frame = ttk.Frame(scoring_notebook)
        scoring_notebook.add(per_cbush_frame, text="Per-CBUSH Analysis")
        
        # CBUSH performance table
        cbush_table_frame = ttk.LabelFrame(per_cbush_frame, text="Per-CBUSH Performance Breakdown")
        cbush_table_frame.pack(fill='both', expand=True, padx=10, pady=10)
        
        cbush_columns = ('CBUSH', 'Model', 'Precision', 'Recall', 'F1-Score', 'ROC AUC', 'Avg Precision', 
                        'True Pos', 'False Pos', 'True Neg', 'False Neg')
        self.cbush_tree = ttk.Treeview(cbush_table_frame, columns=cbush_columns, show='headings', height=15)
        
        for col in cbush_columns:
            self.cbush_tree.heading(col, text=col)
            self.cbush_tree.column(col, width=90)
        
        # Add scrollbars to CBUSH table
        cbush_scroll_v = ttk.Scrollbar(cbush_table_frame, orient='vertical', command=self.cbush_tree.yview)
        cbush_scroll_h = ttk.Scrollbar(cbush_table_frame, orient='horizontal', command=self.cbush_tree.xview)
        self.cbush_tree.configure(yscrollcommand=cbush_scroll_v.set, xscrollcommand=cbush_scroll_h.set)
        
        self.cbush_tree.pack(side='left', fill='both', expand=True, padx=10, pady=10)
        cbush_scroll_v.pack(side='right', fill='y')
        cbush_scroll_h.pack(side='bottom', fill='x')
        
        # Sub-tab 4: Threshold Optimization
        threshold_frame = ttk.Frame(scoring_notebook)
        scoring_notebook.add(threshold_frame, text="Threshold Optimization")
        
        # Threshold optimization controls
        threshold_control_frame = tk.Frame(threshold_frame)
        threshold_control_frame.pack(fill='x', padx=10, pady=10)
        
        tk.Button(threshold_control_frame, text="üéØ Find Optimal Thresholds", 
                 command=self.find_optimal_thresholds,
                 bg='#e74c3c', fg='white', font=('Arial', 12, 'bold')).pack(side='left')
        
        tk.Button(threshold_control_frame, text="üìà Show Threshold Curves", 
                 command=self.show_threshold_curves,
                 bg='#f39c12', fg='white', font=('Arial', 12, 'bold')).pack(side='left', padx=10)
        
        # Threshold results display
        self.threshold_results_text = scrolledtext.ScrolledText(threshold_frame, height=20, width=100,
                                                               font=('Consolas', 9))
        self.threshold_results_text.pack(fill='both', expand=True, padx=10, pady=10)
        
        # Initialize with placeholder text
        self.detailed_metrics_text.insert('1.0', "No models trained yet. Train models in the ML tab to see detailed metrics.")
        self.threshold_results_text.insert('1.0', "No models trained yet. Train models with probability outputs to optimize thresholds.")
    
    def create_prediction_tab(self):
        """Create prediction interface tab."""
        prediction_frame = ttk.Frame(self.notebook)
        self.notebook.add(prediction_frame, text="üîÆ Prediction")
        
        # Title
        title_label = tk.Label(prediction_frame, text="CBUSH Anomaly Prediction", 
                              font=('Arial', 16, 'bold'), fg='#2c3e50')
        title_label.pack(pady=15)
        
        # Model loading section
        model_frame = ttk.LabelFrame(prediction_frame, text="Model Loading")
        model_frame.pack(fill='x', padx=20, pady=15)
        
        # Model source selection
        tk.Label(model_frame, text="Select Model Source:", font=('Arial', 12, 'bold')).pack(anchor='w', padx=10, pady=10)
        
        self.model_source = tk.StringVar(value="memory")
        model_options = [
            ("Use Currently Trained Model", "memory"),
            ("Load Model from File (.pkl/.h5)", "file")
        ]
        
        for text, value in model_options:
            tk.Radiobutton(model_frame, text=text, variable=self.model_source, value=value,
                          font=('Arial', 11)).pack(anchor='w', padx=20, pady=3)
        
        # Load model button
        load_frame = tk.Frame(model_frame)
        load_frame.pack(fill='x', padx=10, pady=10)
        
        tk.Button(load_frame, text="üìÇ Load Model File", command=self.load_model_file,
                 bg='#3498db', fg='white', font=('Arial', 10, 'bold')).pack(side='left')
        
        self.loaded_model_label = tk.Label(load_frame, text="No external model loaded", 
                                          font=('Arial', 9), fg='#7f8c8d')
        self.loaded_model_label.pack(side='left', padx=10)
        
        # Data input section
        input_frame = ttk.LabelFrame(prediction_frame, text="Input Data")
        input_frame.pack(fill='x', padx=20, pady=15)
        
        tk.Label(input_frame, text="Upload CSV Files with Accelerometer and Displacement Data:", 
                font=('Arial', 12, 'bold')).pack(anchor='w', padx=10, pady=10)
        
        # File upload controls
        file_frame = tk.Frame(input_frame)
        file_frame.pack(fill='x', padx=10, pady=10)
        
        # Acceleration file
        accel_frame = tk.Frame(file_frame)
        accel_frame.pack(fill='x', pady=5)
        
        tk.Label(accel_frame, text="Acceleration Results CSV:", font=('Arial', 10, 'bold')).pack(anchor='w')
        accel_input_frame = tk.Frame(accel_frame)
        accel_input_frame.pack(fill='x', pady=3)
        
        self.accel_file_var = tk.StringVar()
        tk.Entry(accel_input_frame, textvariable=self.accel_file_var, width=80).pack(side='left', fill='x', expand=True)
        tk.Button(accel_input_frame, text="Browse", command=self.browse_accel_file).pack(side='right', padx=(5,0))
        
        # Displacement file
        disp_frame = tk.Frame(file_frame)
        disp_frame.pack(fill='x', pady=5)
        
        tk.Label(disp_frame, text="Displacement Results CSV:", font=('Arial', 10, 'bold')).pack(anchor='w')
        disp_input_frame = tk.Frame(disp_frame)
        disp_input_frame.pack(fill='x', pady=3)
        
        self.disp_file_var = tk.StringVar()
        tk.Entry(disp_input_frame, textvariable=self.disp_file_var, width=80).pack(side='left', fill='x', expand=True)
        tk.Button(disp_input_frame, text="Browse", command=self.browse_disp_file).pack(side='right', padx=(5,0))
        
        # Prediction controls
        predict_frame = ttk.LabelFrame(prediction_frame, text="Prediction")
        predict_frame.pack(fill='x', padx=20, pady=15)
        
        tk.Button(predict_frame, text="üéØ Predict CBUSH Condition", 
                 command=self.predict_cbush_condition,
                 bg='#e74c3c', fg='white', font=('Arial', 14, 'bold'),
                 height=2, width=25).pack(pady=15)
        
        # Results display
        results_frame = ttk.LabelFrame(prediction_frame, text="Prediction Results")
        results_frame.pack(fill='both', expand=True, padx=20, pady=15)
        
        self.prediction_results = scrolledtext.ScrolledText(results_frame, height=15, width=100,
                                                           font=('Consolas', 10))
        self.prediction_results.pack(fill='both', expand=True, padx=10, pady=10)
        self.prediction_results.insert('1.0', "No predictions made yet. Upload data and run prediction.")
    
    def create_spatial_tab(self):
        """Create spatial analysis and visualization tab."""
        spatial_frame = ttk.Frame(self.notebook)
        self.notebook.add(spatial_frame, text="üìä Spatial Analysis")
        
        # Title
        title_label = tk.Label(spatial_frame, text="Spatial Response Pattern Analysis", 
                              font=('Arial', 16, 'bold'), fg='#2c3e50')
        title_label.pack(pady=15)
        
        # Visualization controls
        viz_control_frame = ttk.LabelFrame(spatial_frame, text="Visualization Controls")
        viz_control_frame.pack(fill='x', padx=20, pady=15)
        
        # Plot type selection
        tk.Label(viz_control_frame, text="Select Plot Type:", font=('Arial', 12, 'bold')).pack(anchor='w', padx=10, pady=10)
        
        self.spatial_plot_type = tk.StringVar(value="combined")
        spatial_options = [
            ("üåü Combined All Studies", "combined", "All studies on one plot"),
            ("üìä Individual Study Types", "individual", "Separate plots by study type"),
            ("üéØ Single Study Focus", "single", "Focus on one specific study")
        ]
        
        for text, value, description in spatial_options:
            frame = tk.Frame(viz_control_frame)
            frame.pack(anchor='w', padx=20, pady=3)
            
            tk.Radiobutton(frame, text=text, variable=self.spatial_plot_type, value=value,
                          font=('Arial', 11)).pack(anchor='w')
            tk.Label(frame, text=f"   {description}", font=('Arial', 9), 
                    fg='#7f8c8d').pack(anchor='w')
        
        # Generate plots button
        tk.Button(viz_control_frame, text="üìà Generate Spatial Plots", 
                 command=self.generate_spatial_plots,
                 bg='#9b59b6', fg='white', font=('Arial', 12, 'bold'),
                 height=2, width=20).pack(pady=15)
        
        # Plot display area (placeholder)
        plot_frame = ttk.LabelFrame(spatial_frame, text="Generated Plots")
        plot_frame.pack(fill='both', expand=True, padx=20, pady=15)
        
        self.spatial_info = scrolledtext.ScrolledText(plot_frame, height=20, width=100,
                                                     font=('Consolas', 9))
        self.spatial_info.pack(fill='both', expand=True, padx=10, pady=10)
        self.spatial_info.insert('1.0', "No spatial plots generated yet. Process studies and create matrix first.")
    
    def create_results_tab(self):
        """Create enhanced results and visualization tab."""
        results_frame = ttk.Frame(self.notebook)
        self.notebook.add(results_frame, text="üìà Results")
        
        # Results display with tabs
        results_notebook = ttk.Notebook(results_frame)
        results_notebook.pack(fill='both', expand=True, padx=20, pady=15)
        
        # Performance metrics tab
        metrics_frame = ttk.Frame(results_notebook)
        results_notebook.add(metrics_frame, text="Performance Metrics")
        
        self.results_text = scrolledtext.ScrolledText(metrics_frame, height=25, width=100,
                                                     font=('Consolas', 10))
        self.results_text.pack(fill='both', expand=True, padx=10, pady=10)
        
        # Visualizations tab
        viz_frame = ttk.Frame(results_notebook)
        results_notebook.add(viz_frame, text="Visualizations")
        
        # Visualization controls
        viz_controls = tk.Frame(viz_frame)
        viz_controls.pack(fill='x', padx=10, pady=10)
        
        viz_buttons = [
            ("üîç Feature Importance", self.show_feature_importance, '#3498db'),
            ("üìä Confusion Matrix", self.show_confusion_matrix, '#e67e22'),
            ("‚öñÔ∏è Model Comparison", self.show_model_comparison, '#27ae60'),
            ("üìà Training History", self.show_training_history, '#9b59b6')
        ]
        
        for text, command, color in viz_buttons:
            tk.Button(viz_controls, text=text, command=command, bg=color, fg='white',
                     font=('Arial', 10, 'bold')).pack(side='left', padx=5, pady=5)
        
        # Visualization display info
        self.viz_info = scrolledtext.ScrolledText(viz_frame, height=20, width=100,
                                                 font=('Consolas', 9))
        self.viz_info.pack(fill='both', expand=True, padx=10, pady=10)
        self.viz_info.insert('1.0', "Train models to see performance visualizations.")
    
    def create_export_tab(self):
        """Create enhanced export tab."""
        export_frame = ttk.Frame(self.notebook)
        self.notebook.add(export_frame, text="üíæ Export")
        
        # Title
        title_label = tk.Label(export_frame, text="Export Models & Data", 
                              font=('Arial', 16, 'bold'), fg='#2c3e50')
        title_label.pack(pady=15)
        
        # Model export section
        model_export_frame = ttk.LabelFrame(export_frame, text="Model Export")
        model_export_frame.pack(fill='x', padx=20, pady=15)
        
        tk.Label(model_export_frame, text="Export Trained Models:", 
                font=('Arial', 12, 'bold')).pack(anchor='w', padx=10, pady=10)
        
        # Model export buttons
        model_buttons = []
        available_strategies = self.ml_pipeline.ml_strategies
        
        if 'random_forest' in available_strategies:
            model_buttons.append(("üå≥ Export Random Forest (.pkl)", "random_forest", '#27ae60'))
        if 'neural_network' in available_strategies:
            model_buttons.append(("üß† Export Neural Network (.h5)", "neural_network", '#3498db'))
        if 'xgboost' in available_strategies:
            model_buttons.append(("‚ö° Export XGBoost (.pkl)", "xgboost", '#e67e22'))
        
        model_button_frame = tk.Frame(model_export_frame)
        model_button_frame.pack(fill='x', padx=10, pady=10)
        
        for text, model_name, color in model_buttons:
            tk.Button(model_button_frame, text=text, bg=color, fg='white',
                     command=lambda m=model_name: self.export_model(m),
                     font=('Arial', 10, 'bold')).pack(anchor='w', pady=5)
        
        # Data export section
        data_export_frame = ttk.LabelFrame(export_frame, text="Data Export")
        data_export_frame.pack(fill='x', padx=20, pady=15)
        
        tk.Label(data_export_frame, text="Export Data & Analysis:", 
                font=('Arial', 12, 'bold')).pack(anchor='w', padx=10, pady=10)
        
        data_buttons = [
            ("üìä Export Master Matrix (CSV)", self.export_master_matrix, '#16a085'),
            ("üìà Export Results Summary", self.export_results_summary, '#9b59b6'),
            ("üîç Export Feature Importance", self.export_feature_importance, '#f39c12'),
            ("üìã Export Complete Report", self.export_complete_report, '#e74c3c')
        ]
        
        data_button_frame = tk.Frame(data_export_frame)
        data_button_frame.pack(fill='x', padx=10, pady=10)
        
        for text, command, color in data_buttons:
            tk.Button(data_button_frame, text=text, command=command, bg=color, fg='white',
                     font=('Arial', 10, 'bold')).pack(anchor='w', pady=5)
        
        # Deployment information
        deployment_frame = ttk.LabelFrame(export_frame, text="Spacecraft Deployment Guide")
        deployment_frame.pack(fill='both', expand=True, padx=20, pady=15)
        
        deployment_text = f"""
üöÄ SPACECRAFT DEPLOYMENT GUIDE

üìä Available Models:
{chr(10).join([f'   ‚Ä¢ {name}' for name in available_strategies.values()])}

üîß Model Usage:
   1. Random Forest (.pkl): Use with scikit-learn
      ‚îî‚îÄ joblib.load('model.pkl')

   2. Neural Network (.h5): Use with TensorFlow
      ‚îî‚îÄ tensorflow.keras.models.load_model('model.h5')

   3. XGBoost (.pkl): Use with XGBoost library
      ‚îî‚îÄ joblib.load('model.pkl')

üìã Deployment Steps:
   1. Export trained model using buttons above
   2. Include feature_matrix_builder.py for preprocessing
   3. Apply same feature extraction to new accelerometer data
   4. Use model.predict() for CBUSH anomaly detection
   5. Implement confidence thresholds for decision making

üéØ Multi-Label Output:
   ‚Ä¢ Model predicts loose CBUSHes: [CBUSH_2, CBUSH_3, ..., CBUSH_10]
   ‚Ä¢ Each CBUSH gets probability score (0.0 - 1.0)
   ‚Ä¢ Threshold at 0.5 for binary classification
   ‚Ä¢ Use ensemble methods for highest reliability

‚úÖ Offline Ready: All exports work without internet connection
üõ°Ô∏è Spacecraft Ready: Designed for real-time bolt health monitoring
        """
        
        deployment_display = scrolledtext.ScrolledText(deployment_frame, height=25, width=100,
                                                      font=('Consolas', 9))
        deployment_display.pack(fill='both', expand=True, padx=10, pady=10)
        deployment_display.insert('1.0', deployment_text)
        deployment_display.configure(state='disabled')
    
    # Event handlers and utility methods
    
    def browse_study_path(self, study_folder):
        """Browse for study folder path."""
        path = filedialog.askdirectory(title=f"Select {study_folder} Folder (containing POST_0)")
        if path:
            self.study_path_vars[study_folder].set(path)
    
    def initialize_processor(self):
        """Initialize the processor with all study paths."""
        try:
            # Validate all paths are set
            missing_paths = []
            for folder in ['Study1', 'Study2', 'Study3']:
                path = self.study_path_vars[folder].get().strip()
                if not path:
                    missing_paths.append(folder)
                elif not os.path.exists(path):
                    missing_paths.append(f"{folder} (path not found)")
                elif not os.path.exists(os.path.join(path, "POST_0")):
                    missing_paths.append(f"{folder} (POST_0 not found)")
                else:
                    self.processor.set_study_path(folder, path)
            
            if missing_paths:
                messagebox.showerror("Error", f"Invalid paths for: {', '.join(missing_paths)}")
                return
            
            # Validate processor
            self.processor.validate_study_paths()
            
            self.log_message("‚úÖ Processor initialized successfully!")
            for folder in ['Study1', 'Study2', 'Study3']:
                path = self.study_path_vars[folder].get()
                self.log_message(f"   {folder}: {path}")
            
            self.update_studies_display()
            messagebox.showinfo("Success", "Processor initialized successfully!")
            
        except Exception as e:
            error_msg = f"Failed to initialize processor: {str(e)}"
            self.log_message(f"‚ùå {error_msg}")
            messagebox.showerror("Error", error_msg)
    
    def select_study_type(self, study_type):
        """Select all studies of a specific type."""
        if study_type == 'single':
            studies = ['S1A', 'S1B', 'S1C', 'S1D', 'S1E', 'S1F', 'S1G', 'S1H', 'S1I']
        elif study_type == 'adjacent':
            studies = ['S2A', 'S2B', 'S2C', 'S2D', 'S2E', 'S2F', 'S2G', 'S2H']
        elif study_type == 'multibolt':
            studies = ['S3A', 'S3B', 'S3C']
        else:
            return
        
        for study_id in studies:
            if study_id in self.study_vars:
                self.study_vars[study_id].set(True)
    
    def select_all_studies(self):
        """Select all available studies."""
        for var in self.study_vars.values():
            var.set(True)
    
    def clear_all_studies(self):
        """Clear all study selections."""
        for var in self.study_vars.values():
            var.set(False)
    
    def process_selected_studies(self):
        """Process selected studies in background thread."""
        try:
            self.processor.validate_study_paths()
        except Exception as e:
            messagebox.showerror("Error", f"Processor not properly initialized: {e}")
            return
        
        selected_studies = [study_id for study_id, var in self.study_vars.items() if var.get()]
        
        if not selected_studies:
            messagebox.showerror("Error", "Please select at least one study")
            return
        
        # Start processing
        self.progress_bar.configure(mode='indeterminate')
        self.progress_bar.start()
        self.progress_label.config(text="Initializing processing...")
        
        self.processing_thread = threading.Thread(target=self._process_studies_thread, 
                                                 args=(selected_studies,))
        self.processing_thread.daemon = True
        self.processing_thread.start()
    
    def _process_studies_thread(self, selected_studies):
        """Process studies in background thread."""
        try:
            self.log_message(f"üîÑ Starting processing of {len(selected_studies)} studies...")
            
            total_studies = len(selected_studies)
            for i, study_id in enumerate(selected_studies):
                self.root.after(0, lambda i=i, total=total_studies, study=study_id: 
                               self.progress_label.config(text=f"Processing {study} ({i+1}/{total})..."))
                
                self.log_message(f"Processing {study_id}...")
                
                result = self.processor.process_study_batch(study_id)
                
                if result is not None:
                    self.log_message(f"‚úÖ {study_id} completed: {len(result)} designs")
                else:
                    self.log_message(f"‚ùå {study_id} failed")
                
                # Update progress
                progress = ((i + 1) / total_studies) * 100
                self.root.after(0, lambda p=progress: self.progress_var.set(p))
            
            self.log_message("‚úÖ All selected studies processed successfully!")
            self.root.after(0, self._processing_complete)
            
        except Exception as e:
            error_msg = f"Processing error: {str(e)}"
            self.log_message(f"‚ùå {error_msg}")
            self.root.after(0, lambda: self._processing_failed(error_msg))
    
    def _processing_complete(self):
        """Handle processing completion on main thread."""
        self.progress_bar.stop()
        self.progress_bar.configure(mode='determinate')
        self.progress_var.set(100)
        self.progress_label.config(text="Processing completed!")
        self.update_studies_display()
        messagebox.showinfo("Complete", "Study processing completed successfully!")
    
    def _processing_failed(self, error_msg):
        """Handle processing failure on main thread."""
        self.progress_bar.stop()
        self.progress_bar.configure(mode='determinate')
        self.progress_var.set(0)
        self.progress_label.config(text="Processing failed!")
        messagebox.showerror("Processing Failed", error_msg)
    
    def update_studies_display(self):
        """Update the studies tree view display."""
        # Clear existing items
        for item in self.studies_tree.get_children():
            self.studies_tree.delete(item)
        
        # Get available studies
        studies_by_type = self.processor.get_available_studies()
        
        for study_type, studies in studies_by_type.items():
            for study in studies:
                status = "‚úÖ Processed" if study['processed'] else "‚è≥ Pending"
                design_count = len(self.processor.processed_data.get(study['id'], []))
                folder = study.get('study_folder', 'Unknown')
                
                self.studies_tree.insert('', 'end', values=(
                    study['id'],
                    study_type.title(),
                    '-'.join(map(str, study['cbush'])),
                    design_count if study['processed'] else 0,
                    status,
                    folder
                ))
    
    def create_master_matrix(self):
        """Create master matrix from processed studies."""
        if not self.processor.processed_data:
            messagebox.showerror("Error", "No processed studies available. Process studies first.")
            return
        
        try:
            matrix_type = self.matrix_type.get()
            self.current_data = self.processor.create_master_matrix(matrix_type=matrix_type)
            
            if self.current_data is not None:
                # Display matrix information
                info_text = self._generate_matrix_info_text(self.current_data, matrix_type)
                
                self.matrix_info_text.delete('1.0', tk.END)
                self.matrix_info_text.insert('1.0', info_text)
                
                self.log_message(f"‚úÖ {matrix_type.title()} matrix created successfully!")
                self.log_message(f"   Dimensions: {self.current_data.shape}")
                messagebox.showinfo("Success", f"{matrix_type.title()} matrix created successfully!")
            else:
                messagebox.showerror("Error", "Failed to create master matrix")
                
        except Exception as e:
            error_msg = f"Failed to create master matrix: {str(e)}"
            self.log_message(f"‚ùå {error_msg}")
            messagebox.showerror("Error", error_msg)
    
    def _generate_matrix_info_text(self, df, matrix_type):
        """Generate detailed matrix information text."""
        info_lines = [
            f"=== {matrix_type.upper()} MATRIX INFORMATION ===",
            f"",
            f"üìä Basic Statistics:",
            f"   Total Designs: {len(df)}",
            f"   Total Features: {len(df.columns)}",
            f"   Matrix Type: {matrix_type.title()}",
            f"",
            f"üìã Study Composition:"
        ]
        
        # Study composition
        if 'study_type' in df.columns:
            study_counts = df['study_type'].value_counts()
            for study_type, count in study_counts.items():
                percentage = (count / len(df)) * 100
                info_lines.append(f"   {study_type.title()}: {count} designs ({percentage:.1f}%)")
        
        info_lines.append("")
        info_lines.append("üéØ CBUSH Involvement (Multi-Label):")
        
        # CBUSH involvement
        cbush_involvement = {}
        for cbush_num in range(2, 11):
            col_name = f'cbush_{cbush_num}_loose'
            if col_name in df.columns:
                count = df[col_name].sum()
                percentage = (count / len(df)) * 100
                info_lines.append(f"   CBUSH {cbush_num}: {count} designs ({percentage:.1f}%)")
        
        info_lines.append("")
        info_lines.append("üîç Feature Categories:")
        
        # Feature analysis
        feature_types = {}
        feature_cols = [col for col in df.columns if col.startswith(('ACCE_', 'DISP_'))]
        
        for col in feature_cols:
            if 'ACCE_T1_PSD' in col:
                feature_types['Modal (PSD)'] = feature_types.get('Modal (PSD)', 0) + 1
            elif 'ACCE_T1_Area' in col:
                feature_types['Energy (Area)'] = feature_types.get('Energy (Area)', 0) + 1
            elif 'DISP_' in col:
                feature_types['Displacement'] = feature_types.get('Displacement', 0) + 1
        
        for feature_type, count in feature_types.items():
            info_lines.append(f"   {feature_type}: {count} features")
        
        info_lines.append("")
        info_lines.append("‚úÖ Ready for Multi-Label Classification!")
        info_lines.append("   ‚Üí Each design can have multiple loose CBUSHes")
        info_lines.append("   ‚Üí Perfect for spacecraft deployment scenarios")
        
        return "\n".join(info_lines)
    
    def save_matrix_csv(self):
        """Save current matrix to CSV file."""
        if self.current_data is None:
            messagebox.showerror("Error", "No matrix available. Create matrix first.")
            return
        
        matrix_type = self.matrix_type.get()
        default_filename = f"master_matrix_{matrix_type}_{len(self.current_data)}_designs.csv"
        
        filename = filedialog.asksaveasfilename(
            title="Save Master Matrix",
            defaultextension=".csv",
            filetypes=[("CSV Files", "*.csv")],
            initialname=default_filename
        )
        
        if filename:
            try:
                self.current_data.to_csv(filename, index=False)
                self.log_message(f"‚úÖ Matrix saved: {filename}")
                messagebox.showinfo("Success", f"Matrix saved successfully!\n{filename}")
            except Exception as e:
                error_msg = f"Failed to save matrix: {str(e)}"
                self.log_message(f"‚ùå {error_msg}")
                messagebox.showerror("Error", error_msg)
    
    def train_model(self):
        """Train selected ML model."""
        if self.current_data is None:
            messagebox.showerror("Error", "No matrix available. Create master matrix first.")
            return
        
        # Start training in background thread
        self.training_progress_bar.configure(mode='indeterminate')
        self.training_progress_bar.start()
        self.model_status_var.set("üîÑ Training in progress...")
        
        strategy = self.ml_strategy.get()
        classification_type = self.classification_type.get()
        
        self.training_thread = threading.Thread(target=self._train_model_thread, 
                                              args=(strategy, classification_type))
        self.training_thread.daemon = True
        self.training_thread.start()
    
    def _train_model_thread(self, strategy, classification_type):
        """Train model in background thread."""
        try:
            self.log_message(f"üß† Training {strategy} model...")
            self.log_message(f"   Classification type: {classification_type}")
            self.log_message(f"   Dataset size: {len(self.current_data)} designs")
            
            # Load data into ML pipeline
            self.ml_pipeline.load_data(self.current_data)
            self.ml_pipeline.prepare_targets(classification_type)
            
            # Train selected strategy
            if strategy == 'random_forest':
                model, results = self.ml_pipeline.train_random_forest()
            elif strategy == 'neural_network':
                model, results = self.ml_pipeline.train_neural_network()
            elif strategy == 'xgboost':
                model, results = self.ml_pipeline.train_xgboost()
            elif strategy == 'ensemble':
                model, results = self.ml_pipeline.train_ensemble()
            else:
                raise ValueError(f"Unknown strategy: {strategy}")
            
            # Update UI on main thread
            self.root.after(0, self._training_complete, strategy, results)
            
        except Exception as e:
            error_msg = f"Training error: {str(e)}"
            self.log_message(f"‚ùå {error_msg}")
            self.root.after(0, self._training_failed, error_msg)
    
    def _training_complete(self, strategy, results):
        """Handle training completion on main thread."""
        self.training_progress_bar.stop()
        
        # Extract key metrics based on classification mode
        if self.ml_pipeline.classification_mode == 'multilabel':
            main_metric = results.get('jaccard_score', 0)
            metric_name = "Jaccard Score"
            hamming_loss = results.get('hamming_loss', 0)
            status_text = f"‚úÖ {strategy.title()} trained - {metric_name}: {main_metric:.3f}, Hamming Loss: {hamming_loss:.3f}"
        else:
            main_metric = results.get('accuracy', 0)
            metric_name = "Accuracy"
            status_text = f"‚úÖ {strategy.title()} trained - {metric_name}: {main_metric:.3f}"
        
        self.model_status_var.set(status_text)
        self.log_message(status_text)
        
        # Display detailed results
        self.display_training_results(results)
        
        # Automatically calculate comprehensive scores
        self.log_message("üîÑ Auto-calculating comprehensive scores...")
        self.calculate_comprehensive_scores()
        
        messagebox.showinfo("Success", f"Model training completed!\n{metric_name}: {main_metric:.1%}\n\nComprehensive scores calculated automatically.")
    
    def _training_failed(self, error_msg):
        """Handle training failure on main thread."""
        self.training_progress_bar.stop()
        self.model_status_var.set("‚ùå Training failed")
        messagebox.showerror("Training Failed", error_msg)
    
    def display_training_results(self, results):
        """Display comprehensive training results."""
        self.results_text.delete(1.0, tk.END)
        
        result_lines = [
            f"=== MODEL TRAINING RESULTS ===",
            f"",
            f"Model: {results.get('model_name', 'Unknown')}",
            f"Classification Mode: {self.ml_pipeline.classification_mode}",
            f"Training Time: {time.strftime('%Y-%m-%d %H:%M:%S')}",
            f""
        ]
        
        if self.ml_pipeline.classification_mode == 'multilabel':
            result_lines.extend([
                "üìä Multi-Label Classification Metrics:",
                f"   Jaccard Score (IoU): {results.get('jaccard_score', 0):.3f}",
                f"   Hamming Loss: {results.get('hamming_loss', 0):.3f}",
                f"   F1-Score (Macro): {results.get('f1_score', 0):.3f}",
                f"   Precision (Macro): {results.get('precision', 0):.3f}",
                f"   Recall (Macro): {results.get('recall', 0):.3f}",
                f"   Exact Match Accuracy: {results.get('exact_match_accuracy', 0):.3f}",
                f""
            ])
        else:
            result_lines.extend([
                "üìä Single-Label Classification Metrics:",
                f"   Accuracy: {results.get('accuracy', 0):.3f}",
                f""
            ])
        
        # Add classification report if available
        if 'classification_report' in results and isinstance(results['classification_report'], dict):
            result_lines.append("üìã Detailed Classification Report:")
            result_lines.append("=" * 50)
            
            report = results['classification_report']
            if 'macro avg' in report:
                macro_avg = report['macro avg']
                result_lines.extend([
                    f"Macro Average:",
                    f"   Precision: {macro_avg.get('precision', 0):.3f}",
                    f"   Recall: {macro_avg.get('recall', 0):.3f}",
                    f"   F1-Score: {macro_avg.get('f1-score', 0):.3f}",
                    f""
                ])
        
        # Add training history for neural networks
        if 'training_epochs' in results:
            result_lines.extend([
                f"üß† Neural Network Training:",
                f"   Epochs: {results['training_epochs']}",
                f"   Early stopping: {'Yes' if results['training_epochs'] < 150 else 'No'}",
                f""
            ])
        
        result_lines.extend([
            "üéØ Model Ready for:",
            "   ‚úÖ CBUSH anomaly detection",
            "   ‚úÖ Multi-bolt failure scenarios", 
            "   ‚úÖ Spacecraft deployment",
            "   ‚úÖ Real-time monitoring"
        ])
        
        self.results_text.insert(1.0, "\n".join(result_lines))
    
    # Additional methods for prediction, visualization, and export
    
    def calculate_comprehensive_scores(self):
        """Calculate comprehensive scores for all trained models."""
        if not self.ml_pipeline.models:
            messagebox.showwarning("Warning", "No trained models available. Train models first.")
            return
        
        if self.current_data is None:
            messagebox.showerror("Error", "No dataset available. Create master matrix first.")
            return
        
        try:
            self.log_message("üìä Calculating comprehensive scores for all models...")
            
            # Prepare data for scoring
            X = self.current_data[[col for col in self.current_data.columns 
                                  if col.startswith(('ACCE_', 'DISP_'))]].values
            
            # Get true labels for multi-label
            if self.ml_pipeline.classification_mode == 'multilabel':
                cbush_cols = [f'cbush_{cbush_num}_loose' for cbush_num in range(2, 11)]
                available_cols = [col for col in cbush_cols if col in self.current_data.columns]
                y_true = self.current_data[available_cols].values
            else:
                y_true = self.current_data['varied_cbush'].values
            
            # Scale features
            X_scaled = self.ml_pipeline.scaler.transform(X)
            
            # Calculate scores for each model
            self.comprehensive_scores = {}
            
            for model_name, model in self.ml_pipeline.models.items():
                self.log_message(f"   Calculating scores for {model_name}...")
                
                # Get predictions
                if model_name == 'neural_network':
                    if self.ml_pipeline.classification_mode == 'multilabel':
                        y_prob = model.predict(X_scaled)
                        y_pred = (y_prob > 0.5).astype(int)
                    else:
                        y_prob = model.predict(X_scaled)
                        y_pred = np.argmax(y_prob, axis=1)
                        y_prob = np.max(y_prob, axis=1)
                else:
                    y_pred = model.predict(X_scaled)
                    try:
                        if hasattr(model, 'predict_proba'):
                            if self.ml_pipeline.classification_mode == 'multilabel':
                                # Multi-output classifier
                                y_prob_list = model.predict_proba(X_scaled)
                                y_prob = np.array([proba[:, 1] for proba in y_prob_list]).T
                            else:
                                y_prob = model.predict_proba(X_scaled)
                        else:
                            y_prob = None
                    except:
                        y_prob = None
                
                # Calculate comprehensive metrics
                metrics = self.scoring_system.calculate_comprehensive_metrics(
                    y_true, y_pred, y_prob, model_name)
                
                self.comprehensive_scores[model_name] = metrics
            
            # Update displays
            self.update_comparison_table()
            self.update_model_selector()
            self.update_per_cbush_table()
            
            self.log_message("‚úÖ Comprehensive scores calculated successfully!")
            messagebox.showinfo("Success", f"Calculated comprehensive scores for {len(self.comprehensive_scores)} models!")
            
        except Exception as e:
            error_msg = f"Failed to calculate comprehensive scores: {str(e)}"
            self.log_message(f"‚ùå {error_msg}")
            messagebox.showerror("Error", error_msg)
    
    def update_comparison_table(self):
        """Update the model comparison table."""
        # Clear existing items
        for item in self.comparison_tree.get_children():
            self.comparison_tree.delete(item)
        
        if not self.comprehensive_scores:
            return
        
        # Add data for each model
        for model_name, metrics in self.comprehensive_scores.items():
            # Determine deployment readiness
            exact_match = metrics.get('exact_match_ratio', 0)
            jaccard = metrics.get('jaccard_score', 0)
            f1_macro = metrics.get('f1_macro', 0)
            
            deployment_ready = (exact_match >= 0.6 and jaccard >= 0.5 and f1_macro >= 0.6)
            readiness_text = "‚úÖ Ready" if deployment_ready else "‚ö†Ô∏è Not Ready"
            
            values = (
                model_name.title(),
                f"{exact_match:.3f}",
                f"{jaccard:.3f}",
                f"{metrics.get('hamming_loss', 0):.3f}",
                f"{f1_macro:.3f}",
                f"{metrics.get('precision_macro', 0):.3f}",
                f"{metrics.get('recall_macro', 0):.3f}",
                f"{metrics.get('roc_auc_macro', 0):.3f}" if 'roc_auc_macro' in metrics else "N/A",
                readiness_text
            )
            
            self.comparison_tree.insert('', 'end', values=values)
    
    def update_model_selector(self):
        """Update the model selector combobox."""
        model_names = [name.title() for name in self.comprehensive_scores.keys()]
        self.model_selector['values'] = model_names
        if model_names:
            self.model_selector.set(model_names[0])
            self.update_detailed_metrics()
    
    def update_detailed_metrics(self, event=None):
        """Update the detailed metrics display."""
        selected_model = self.selected_model_for_details.get().lower()
        
        if selected_model in self.comprehensive_scores:
            metrics = self.comprehensive_scores[selected_model]
            detailed_report = self.scoring_system.create_detailed_report(metrics, selected_model)
            
            self.detailed_metrics_text.delete('1.0', tk.END)
            self.detailed_metrics_text.insert('1.0', detailed_report)
    
    def update_per_cbush_table(self):
        """Update the per-CBUSH performance table."""
        # Clear existing items
        for item in self.cbush_tree.get_children():
            self.cbush_tree.delete(item)
        
        if not self.comprehensive_scores:
            return
        
        # Add data for each CBUSH and model combination
        for model_name, metrics in self.comprehensive_scores.items():
            if 'per_label_metrics' in metrics:
                for cbush_name, cbush_metrics in metrics['per_label_metrics'].items():
                    # Get confusion matrix data if available
                    cm_data = metrics.get('confusion_matrices', {}).get(cbush_name, {})
                    
                    values = (
                        cbush_name.replace('CBUSH_', ''),
                        model_name.title(),
                        f"{cbush_metrics.get('precision', 0):.3f}",
                        f"{cbush_metrics.get('recall', 0):.3f}",
                        f"{cbush_metrics.get('f1', 0):.3f}",
                        f"{cbush_metrics.get('roc_auc', 0):.3f}" if 'roc_auc' in cbush_metrics else "N/A",
                        f"{cbush_metrics.get('avg_precision', 0):.3f}" if 'avg_precision' in cbush_metrics else "N/A",
                        str(cm_data.get('true_positive', 0)),
                        str(cm_data.get('false_positive', 0)),
                        str(cm_data.get('true_negative', 0)),
                        str(cm_data.get('false_negative', 0))
                    )
                    
                    self.cbush_tree.insert('', 'end', values=values)
    
    def generate_score_visualizations(self):
        """Generate comprehensive score visualizations."""
        if not self.comprehensive_scores:
            messagebox.showwarning("Warning", "No comprehensive scores available. Calculate scores first.")
            return
        
        try:
            self.log_message("üìä Generating comprehensive score visualizations...")
            
            plots_created = self.scoring_system.create_performance_visualization(
                self.comprehensive_scores, save_plots=True)
            
            if plots_created:
                self.log_message(f"‚úÖ Generated {len(plots_created)} visualization plots:")
                for plot in plots_created:
                    self.log_message(f"   üìà {plot}")
                
                messagebox.showinfo("Success", f"Generated {len(plots_created)} visualization plots!\nCheck current directory for PNG files.")
            else:
                messagebox.showwarning("Warning", "No visualizations generated.")
                
        except Exception as e:
            error_msg = f"Failed to generate visualizations: {str(e)}"
            self.log_message(f"‚ùå {error_msg}")
            messagebox.showerror("Error", error_msg)
    
    def find_optimal_thresholds(self):
        """Find optimal prediction thresholds for each CBUSH."""
        if not self.comprehensive_scores:
            messagebox.showwarning("Warning", "No models available. Train models first.")
            return
        
        try:
            self.log_message("üéØ Finding optimal thresholds for all models...")
            
            # Get data for threshold optimization
            X = self.current_data[[col for col in self.current_data.columns 
                                  if col.startswith(('ACCE_', 'DISP_'))]].values
            
            cbush_cols = [f'cbush_{cbush_num}_loose' for cbush_num in range(2, 11)]
            available_cols = [col for col in cbush_cols if col in self.current_data.columns]
            y_true = self.current_data[available_cols].values
            
            X_scaled = self.ml_pipeline.scaler.transform(X)
            
            threshold_results_text = []
            threshold_results_text.append("üéØ OPTIMAL THRESHOLD ANALYSIS")
            threshold_results_text.append("=" * 60)
            threshold_results_text.append("")
            
            for model_name, model in self.ml_pipeline.models.items():
                if hasattr(model, 'predict_proba') or model_name == 'neural_network':
                    threshold_results_text.append(f"üìä {model_name.upper()} MODEL:")
                    threshold_results_text.append("-" * 40)
                    
                    # Get probabilities
                    if model_name == 'neural_network':
                        y_prob = model.predict(X_scaled)
                    else:
                        if self.ml_pipeline.classification_mode == 'multilabel':
                            y_prob_list = model.predict_proba(X_scaled)
                            y_prob = np.array([proba[:, 1] for proba in y_prob_list]).T
                        else:
                            y_prob = model.predict_proba(X_scaled)
                    
                    # Find optimal thresholds
                    optimal_thresholds, _ = self.scoring_system.find_optimal_thresholds(
                        y_true, y_prob, model_name)
                    
                    threshold_results_text.append(f"{'CBUSH':<8} {'Threshold':<12} {'F1-Score':<10}")
                    threshold_results_text.append("-" * 32)
                    
                    for cbush_name, threshold_data in optimal_thresholds.items():
                        cbush_num = cbush_name.replace('CBUSH_', '')
                        threshold = threshold_data['threshold']
                        f1_score = threshold_data['f1_score']
                        threshold_results_text.append(f"{cbush_num:<8} {threshold:<12.3f} {f1_score:<10.3f}")
                    
                    threshold_results_text.append("")
                else:
                    threshold_results_text.append(f"‚ö†Ô∏è  {model_name.upper()}: No probability output for threshold optimization")
                    threshold_results_text.append("")
            
            threshold_results_text.extend([
                "üí° USAGE RECOMMENDATIONS:",
                "   ‚Ä¢ Use these thresholds instead of default 0.5 for better performance",
                "   ‚Ä¢ Higher thresholds = fewer false positives, more false negatives",
                "   ‚Ä¢ Lower thresholds = more false positives, fewer false negatives",
                "   ‚Ä¢ For spacecraft: Consider safety requirements when choosing thresholds",
                "",
                "üöÄ SPACECRAFT DEPLOYMENT:",
                "   ‚Ä¢ Conservative: Use higher thresholds to avoid false alarms",
                "   ‚Ä¢ Sensitive: Use lower thresholds to catch all potential issues",
                "   ‚Ä¢ Balanced: Use optimized thresholds shown above"
            ])
            
            self.threshold_results_text.delete('1.0', tk.END)
            self.threshold_results_text.insert('1.0', "\n".join(threshold_results_text))
            
            self.log_message("‚úÖ Optimal thresholds calculated successfully!")
            
        except Exception as e:
            error_msg = f"Failed to find optimal thresholds: {str(e)}"
            self.log_message(f"‚ùå {error_msg}")
            messagebox.showerror("Error", error_msg)
    
    def show_threshold_curves(self):
        """Show precision-recall and ROC curves for threshold analysis."""
        messagebox.showinfo("Info", "Threshold curves visualization will open in separate windows.\nThis feature creates Precision-Recall and ROC curves for each CBUSH.")
        # Implementation would create matplotlib windows with PR and ROC curves
        # This is a placeholder - full implementation would require significant additional code
    
    def browse_accel_file(self):
        """Browse for acceleration results CSV file."""
        filename = filedialog.askopenfilename(
            title="Select Acceleration Results CSV",
            filetypes=[("CSV Files", "*.csv")]
        )
        if filename:
            self.accel_file_var.set(filename)
    
    def browse_disp_file(self):
        """Browse for displacement results CSV file."""
        filename = filedialog.askopenfilename(
            title="Select Displacement Results CSV", 
            filetypes=[("CSV Files", "*.csv")]
        )
        if filename:
            self.disp_file_var.set(filename)
    
    def load_model_file(self):
        """Load model from file."""
        if self.model_source.get() != "file":
            return
        
        filename = filedialog.askopenfilename(
            title="Select Model File",
            filetypes=[("Pickle Files", "*.pkl"), ("Keras Models", "*.h5")]
        )
        
        if filename:
            try:
                # Determine model name from filename
                model_name = Path(filename).stem
                success = self.ml_pipeline.load_model(model_name, filename)
                
                if success:
                    self.loaded_model_label.config(text=f"Loaded: {Path(filename).name}")
                    self.log_message(f"‚úÖ Model loaded from {filename}")
                else:
                    self.loaded_model_label.config(text="Load failed")
                    
            except Exception as e:
                error_msg = f"Failed to load model: {str(e)}"
                self.log_message(f"‚ùå {error_msg}")
                messagebox.showerror("Error", error_msg)
    
    def predict_cbush_condition(self):
        """Predict CBUSH condition from uploaded CSV files."""
        # Validate inputs
        accel_file = self.accel_file_var.get().strip()
        disp_file = self.disp_file_var.get().strip()
        
        if not accel_file or not disp_file:
            messagebox.showerror("Error", "Please upload both acceleration and displacement CSV files")
            return
        
        if not os.path.exists(accel_file) or not os.path.exists(disp_file):
            messagebox.showerror("Error", "One or both CSV files not found")
            return
        
        # Check if model is available
        if self.model_source.get() == "memory":
            if not self.ml_pipeline.models:
                messagebox.showerror("Error", "No trained model available. Train a model first.")
                return
            model_name = list(self.ml_pipeline.models.keys())[0]  # Use first available model
        else:
            # Use loaded model
            if not self.ml_pipeline.models:
                messagebox.showerror("Error", "No model loaded. Load a model file first.")
                return
            model_name = list(self.ml_pipeline.models.keys())[0]
        
        try:
            # Extract features from uploaded files
            self.log_message("üîÆ Starting CBUSH prediction...")
            self.log_message(f"   Acceleration file: {Path(accel_file).name}")
            self.log_message(f"   Displacement file: {Path(disp_file).name}")
            self.log_message(f"   Using model: {model_name}")
            
            # Import feature extractor
            from feature_matrix_builder import BoltAnomalyFeatureExtractor
            
            # Create temporary extractor (we just need feature extraction, not full processing)
            temp_base_path = Path(accel_file).parent.parent.parent  # Go up to find base path
            extractor = BoltAnomalyFeatureExtractor(str(temp_base_path))
            
            # Extract features
            features = extractor.extract_features_from_files(accel_file, disp_file, design_id=999)
            
            if not features:
                raise ValueError("Failed to extract features from CSV files")
            
            # Get feature matrix in correct order
            feature_cols = [col for col in features.keys() if col.startswith(('ACCE_', 'DISP_'))]
            
            # Ensure feature order matches training data
            if hasattr(self.ml_pipeline, 'feature_names') and self.ml_pipeline.feature_names:
                feature_cols = [col for col in self.ml_pipeline.feature_names if col in features]
            
            X_new = np.array([features[col] for col in feature_cols]).reshape(1, -1)
            
            # Make prediction
            prediction_result = self.ml_pipeline.predict_cbush_condition(X_new, model_name)
            
            if prediction_result is None:
                raise ValueError("Prediction failed")
            
            # Display results
            self._display_prediction_results(prediction_result, model_name, accel_file, disp_file)
            
            self.log_message("‚úÖ CBUSH prediction completed successfully!")
            
        except Exception as e:
            error_msg = f"Prediction failed: {str(e)}"
            self.log_message(f"‚ùå {error_msg}")
            messagebox.showerror("Prediction Failed", error_msg)
    
    def _display_prediction_results(self, prediction_result, model_name, accel_file, disp_file):
        """Display prediction results in a formatted way."""
        self.prediction_results.delete('1.0', tk.END)
        
        result_lines = [
            "üéØ CBUSH ANOMALY PREDICTION RESULTS",
            "=" * 50,
            "",
            f"üìÇ Input Files:",
            f"   Acceleration: {Path(accel_file).name}",
            f"   Displacement: {Path(disp_file).name}",
            "",
            f"ü§ñ Model Used: {model_name.title()}",
            f"üîç Classification Mode: {prediction_result.get('classification_mode', 'Unknown')}",
            f"‚è∞ Prediction Time: {time.strftime('%Y-%m-%d %H:%M:%S')}",
            "",
        ]
        
        if prediction_result.get('classification_mode') == 'multilabel':
            # Multi-label results
            loose_cbushes = prediction_result.get('loose_cbushes', [])
            loose_count = prediction_result.get('loose_count', 0)
            
            result_lines.extend([
                "üö® DETECTED LOOSE CBUSHes:",
                f"   Count: {loose_count}",
                f"   CBUSHes: {loose_cbushes if loose_cbushes else 'None detected'}",
                "",
                "üìä CBUSH PROBABILITIES:"
            ])
            
            # Show probabilities for all CBUSHes
            cbush_probs = prediction_result.get('cbush_probabilities', {})
            for cbush_num in sorted(cbush_probs.keys()):
                prob = cbush_probs[cbush_num]
                status = "üö® LOOSE" if prob > 0.5 else "‚úÖ OK"
                result_lines.append(f"   CBUSH {cbush_num}: {prob:.3f} {status}")
            
            result_lines.extend([
                "",
                "üéØ INTERPRETATION:",
                f"   ‚Ä¢ Threshold: 0.5 (probabilities > 0.5 indicate loose bolts)",
                f"   ‚Ä¢ Multiple bolts can be loose simultaneously",
                f"   ‚Ä¢ Higher probabilities indicate higher confidence",
                ""
            ])
            
            if loose_cbushes:
                result_lines.extend([
                    "‚ö†Ô∏è  RECOMMENDED ACTIONS:",
                    f"   1. Inspect CBUSHes: {', '.join(map(str, loose_cbushes))}",
                    f"   2. Check bolt torque specifications",
                    f"   3. Consider maintenance/replacement",
                    f"   4. Monitor for progressive loosening"
                ])
            else:
                result_lines.extend([
                    "‚úÖ GOOD NEWS:",
                    "   ‚Ä¢ No loose bolts detected",
                    "   ‚Ä¢ All CBUSHes appear properly tightened",
                    "   ‚Ä¢ System within normal parameters"
                ])
                
        else:
            # Single-label results
            predicted_cbush = prediction_result.get('predicted_cbush')
            confidence = prediction_result.get('confidence', 0)
            
            result_lines.extend([
                "üéØ PREDICTION:",
                f"   Most Problematic CBUSH: {predicted_cbush}",
                f"   Confidence: {confidence:.3f}",
                "",
                "üìã INTERPRETATION:",
                f"   ‚Ä¢ CBUSH {predicted_cbush} shows anomalous behavior",
                f"   ‚Ä¢ Confidence level: {confidence:.1%}",
                f"   ‚Ä¢ Recommend focused inspection"
            ])
        
        result_lines.extend([
            "",
            "üöÄ SPACECRAFT DEPLOYMENT NOTES:",
            "   ‚Ä¢ This prediction is based on vibration signature analysis",
            "   ‚Ä¢ Consider environmental factors (temperature, loading)",
            "   ‚Ä¢ Validate with physical inspection when possible",
            "   ‚Ä¢ Use for preventive maintenance scheduling"
        ])
        
        self.prediction_results.insert('1.0', "\n".join(result_lines))
    
    def generate_spatial_plots(self):
        """Generate spatial response pattern plots."""
        if not self.processor.processed_data:
            messagebox.showerror("Error", "No processed studies available")
            return
        
        try:
            plot_type = self.spatial_plot_type.get()
            self.log_message(f"üìà Generating {plot_type} spatial plots...")
            
            # Generate plots using processor
            plots_created = self.processor.create_spatial_analysis(save_plots=True)
            
            if plots_created:
                info_text = f"""
üé® SPATIAL PLOTS GENERATED SUCCESSFULLY!

üìä Generated Plots:
{chr(10).join([f'   ‚úÖ {plot}' for plot in plots_created])}

üìç Plot Locations:
   All plots saved in current working directory

üîç Plot Contents:
   ‚Ä¢ T1_Area response patterns across beam
   ‚Ä¢ Individual study type comparisons  
   ‚Ä¢ Combined analysis of all studies
   ‚Ä¢ Spatial signatures for each CBUSH

üìà Analysis Insights:
   ‚Ä¢ Each CBUSH has unique spatial signature
   ‚Ä¢ Loose bolts show characteristic response patterns
   ‚Ä¢ Multiple loose bolts create combined effects
   ‚Ä¢ Spatial data enables accurate localization

üöÄ Usage for Spacecraft:
   ‚Ä¢ Compare unknown signals to these patterns
   ‚Ä¢ Use for bolt location identification
   ‚Ä¢ Validate ML predictions with spatial analysis
   ‚Ä¢ Optimize sensor placement strategies
                """
                
                self.spatial_info.delete('1.0', tk.END)
                self.spatial_info.insert('1.0', info_text)
                
                self.log_message(f"‚úÖ Generated {len(plots_created)} spatial plots")
                messagebox.showinfo("Success", f"Generated {len(plots_created)} spatial plots successfully!")
            else:
                messagebox.showwarning("Warning", "No plots generated. Check processed data.")
                
        except Exception as e:
            error_msg = f"Failed to generate spatial plots: {str(e)}"
            self.log_message(f"‚ùå {error_msg}")
            messagebox.showerror("Error", error_msg)
    
    def show_feature_importance(self):
        """Show feature importance plot."""
        if not self.ml_pipeline.models:
            messagebox.showwarning("Warning", "No trained models available")
            return
        
        # Get feature importance from available model
        importance_df = None
        for model_name in ['random_forest', 'xgboost']:
            if model_name in self.ml_pipeline.models:
                importance_df = self.ml_pipeline.get_feature_importance(model_name)
                break
        
        if importance_df is None:
            messagebox.showwarning("Warning", "No feature importance available from current models")
            return
        
        self._create_feature_importance_plot(importance_df)
    
    def _create_feature_importance_plot(self, importance_df):
        """Create feature importance plot window."""
        plot_window = tk.Toplevel(self.root)
        plot_window.title("Feature Importance Analysis")
        plot_window.geometry("1000x700")
        
        fig, ax = plt.subplots(figsize=(12, 8))
        top_features = importance_df.head(25)
        
        # Create horizontal bar plot
        bars = ax.barh(range(len(top_features)), top_features['importance'])
        ax.set_yticks(range(len(top_features)))
        ax.set_yticklabels(top_features['feature'], fontsize=8)
        ax.set_xlabel('Importance Score', fontsize=12)
        ax.set_title('Top 25 Most Important Features for CBUSH Detection', fontsize=14)
        
        # Color bars by measurement type
        colors = []
        for feature in top_features['feature']:
            if 'ACCE_T1_PSD' in feature:
                colors.append('#3498db')  # Blue for PSD (modal)
            elif 'ACCE_T1_Area' in feature:
                colors.append('#e74c3c')  # Red for Area (energy)
            elif 'DISP_' in feature:
                colors.append('#27ae60')  # Green for displacement
            else:
                colors.append('#95a5a6')  # Gray for others
        
        for bar, color in zip(bars, colors):
            bar.set_color(color)
        
        # Add legend
        from matplotlib.patches import Patch
        legend_elements = [
            Patch(facecolor='#3498db', label='Modal (PSD)'),
            Patch(facecolor='#e74c3c', label='Energy (Area)'),
            Patch(facecolor='#27ae60', label='Displacement')
        ]
        ax.legend(handles=legend_elements, loc='lower right')
        
        plt.tight_layout()
        
        canvas = FigureCanvasTkAgg(fig, plot_window)
        canvas.draw()
        canvas.get_tk_widget().pack(fill='both', expand=True)
    
    def show_confusion_matrix(self):
        """Show confusion matrix plot."""
        messagebox.showinfo("Info", "Confusion matrix visualization not available for multi-label classification. Use model comparison instead.")
    
    def show_model_comparison(self):
        """Show model comparison chart."""
        if not self.ml_pipeline.results:
            messagebox.showwarning("Warning", "No trained models available")
            return
        
        self._create_model_comparison_plot()
    
    def _create_model_comparison_plot(self):
        """Create model comparison plot window."""
        plot_window = tk.Toplevel(self.root)
        plot_window.title("Model Performance Comparison")
        plot_window.geometry("800x600")
        
        fig, ax = plt.subplots(figsize=(10, 6))
        
        models = []
        scores = []
        metric_name = "Jaccard Score" if self.ml_pipeline.classification_mode == 'multilabel' else "Accuracy"
        
        for model_name, results in self.ml_pipeline.results.items():
            models.append(model_name.replace('_', ' ').title())
            if self.ml_pipeline.classification_mode == 'multilabel':
                scores.append(results.get('jaccard_score', 0))
            else:
                scores.append(results.get('accuracy', 0))
        
        if models:
            bars = ax.bar(models, scores, color=['#3498db', '#e74c3c', '#27ae60', '#f39c12'][:len(models)])
            ax.set_ylabel(metric_name, fontsize=12)
            ax.set_title(f'Model Performance Comparison ({metric_name})', fontsize=14)
            ax.set_ylim(0, 1)
            
            # Add value labels on bars
            for bar, score in zip(bars, scores):
                height = bar.get_height()
                ax.text(bar.get_x() + bar.get_width()/2., height + 0.01,
                       f'{score:.3f}', ha='center', va='bottom', fontweight='bold')
            
            plt.xticks(rotation=45)
            plt.tight_layout()
        
        canvas = FigureCanvasTkAgg(fig, plot_window)
        canvas.draw()
        canvas.get_tk_widget().pack(fill='both', expand=True)
    
    def show_training_history(self):
        """Show training history for neural networks."""
        if 'neural_network' not in self.ml_pipeline.results:
            messagebox.showwarning("Warning", "No neural network training history available")
            return
        
        results = self.ml_pipeline.results['neural_network']
        if 'history' not in results:
            messagebox.showwarning("Warning", "No training history found")
            return
        
        self._create_training_history_plot(results['history'])
    
    def _create_training_history_plot(self, history):
        """Create training history plot window."""
        plot_window = tk.Toplevel(self.root)
        plot_window.title("Neural Network Training History")
        plot_window.geometry("1000x600")
        
        fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(12, 5))
        
        # Loss plot
        epochs = range(1, len(history['loss']) + 1)
        ax1.plot(epochs, history['loss'], 'b-', label='Training Loss')
        if 'val_loss' in history:
            ax1.plot(epochs, history['val_loss'], 'r-', label='Validation Loss')
        ax1.set_title('Training and Validation Loss')
        ax1.set_xlabel('Epochs')
        ax1.set_ylabel('Loss')
        ax1.legend()
        ax1.grid(True)
        
        # Accuracy plot
        if 'accuracy' in history:
            ax2.plot(epochs, history['accuracy'], 'b-', label='Training Accuracy')
        if 'val_accuracy' in history:
            ax2.plot(epochs, history['val_accuracy'], 'r-', label='Validation Accuracy')
        ax2.set_title('Training and Validation Accuracy')
        ax2.set_xlabel('Epochs')
        ax2.set_ylabel('Accuracy')
        ax2.legend()
        ax2.grid(True)
        
        plt.tight_layout()
        
        canvas = FigureCanvasTkAgg(fig, plot_window)
        canvas.draw()
        canvas.get_tk_widget().pack(fill='both', expand=True)
    
    def export_model(self, model_name):
        """Export trained model."""
        if model_name not in self.ml_pipeline.models:
            messagebox.showerror("Error", f"Model {model_name} not trained yet")
            return
        
        # Get file extension based on model type
        if model_name == 'neural_network':
            filetypes = [("Keras Model", "*.h5")]
            default_ext = ".h5"
        else:
            filetypes = [("Pickle File", "*.pkl")]
            default_ext = ".pkl"
        
        # Generate default filename
        matrix_type = getattr(self, 'matrix_type', tk.StringVar(value='combined')).get()
        timestamp = time.strftime("%Y%m%d_%H%M%S")
        default_name = f"{model_name}_{matrix_type}_{timestamp}{default_ext}"
        
        filename = filedialog.asksaveasfilename(
            title=f"Export {model_name.title()} Model",
            filetypes=filetypes,
            defaultextension=default_ext,
            initialname=default_name
        )
        
        if filename:
            success = self.ml_pipeline.save_model(model_name, filename)
            if success:
                self.log_message(f"‚úÖ Model exported: {filename}")
                messagebox.showinfo("Success", f"Model exported successfully!\n{filename}")
            else:
                messagebox.showerror("Error", "Failed to export model")
    
    def export_master_matrix(self):
        """Export master matrix to CSV."""
        if self.current_data is None:
            messagebox.showerror("Error", "No master matrix available")
            return
        
        matrix_type = getattr(self, 'matrix_type', tk.StringVar(value='combined')).get()
        timestamp = time.strftime("%Y%m%d_%H%M%S")
        default_name = f"master_matrix_{matrix_type}_{len(self.current_data)}designs_{timestamp}.csv"
        
        filename = filedialog.asksaveasfilename(
            title="Export Master Matrix",
            filetypes=[("CSV Files", "*.csv")],
            defaultextension=".csv",
            initialname=default_name
        )
        
        if filename:
            try:
                self.current_data.to_csv(filename, index=False)
                self.log_message(f"‚úÖ Matrix exported: {filename}")
                messagebox.showinfo("Success", f"Master matrix exported successfully!\n{filename}")
            except Exception as e:
                error_msg = f"Failed to export matrix: {str(e)}"
                self.log_message(f"‚ùå {error_msg}")
                messagebox.showerror("Error", error_msg)
    
    def export_results_summary(self):
        """Export comprehensive results summary."""
        if not self.ml_pipeline.results:
            messagebox.showerror("Error", "No results available")
            return
        
        timestamp = time.strftime("%Y%m%d_%H%M%S")
        default_name = f"results_summary_{timestamp}.txt"
        
        filename = filedialog.asksaveasfilename(
            title="Export Results Summary",
            filetypes=[("Text Files", "*.txt")],
            defaultextension=".txt",
            initialname=default_name
        )
        
        if filename:
            try:
                summary = self.ml_pipeline.create_results_summary()
                
                with open(filename, 'w') as f:
                    f.write("MULTI-CBUSH BOLT DETECTION RESULTS SUMMARY\n")
                    f.write("=" * 60 + "\n\n")
                    f.write(f"Generated: {time.strftime('%Y-%m-%d %H:%M:%S')}\n\n")
                    
                    f.write(f"Dataset Information:\n")
                    f.write(f"   Classification Mode: {summary.get('classification_mode', 'Unknown')}\n")
                    f.write(f"   Models Trained: {', '.join(summary.get('models_trained', []))}\n")
                    if hasattr(self, 'current_data') and self.current_data is not None:
                        f.write(f"   Total Designs: {len(self.current_data)}\n")
                        f.write(f"   Features: {len([col for col in self.current_data.columns if col.startswith(('ACCE_', 'DISP_'))])}\n")
                    f.write("\n")
                    
                    f.write("Model Performance:\n")
                    f.write("-" * 30 + "\n")
                    
                    for model_name, metrics in summary.get('model_comparison', {}).items():
                        f.write(f"{model_name.title()}:\n")
                        if summary.get('classification_mode') == 'multilabel':
                            f.write(f"   Jaccard Score: {metrics.get('jaccard_score', 0):.3f}\n")
                            f.write(f"   Hamming Loss: {metrics.get('hamming_loss', 0):.3f}\n")
                            f.write(f"   F1-Score: {metrics.get('f1_score', 0):.3f}\n")
                        else:
                            f.write(f"   Accuracy: {metrics.get('accuracy', 0):.3f}\n")
                        f.write("\n")
                    
                    f.write("Deployment Information:\n")
                    f.write("-" * 30 + "\n")
                    f.write("‚Ä¢ Ready for spacecraft deployment\n")
                    f.write("‚Ä¢ Supports multi-label CBUSH detection\n")
                    f.write("‚Ä¢ Compatible with real-time monitoring\n")
                    f.write("‚Ä¢ Optimized for panel-mounted sensors\n")
                
                self.log_message(f"‚úÖ Results summary exported: {filename}")
                messagebox.showinfo("Success", f"Results summary exported successfully!\n{filename}")
                
            except Exception as e:
                error_msg = f"Failed to export results: {str(e)}"
                self.log_message(f"‚ùå {error_msg}")
                messagebox.showerror("Error", error_msg)
    
    def export_feature_importance(self):
        """Export feature importance to CSV."""
        importance_df = None
        for model_name in ['random_forest', 'xgboost']:
            if model_name in self.ml_pipeline.models:
                importance_df = self.ml_pipeline.get_feature_importance(model_name)
                break
        
        if importance_df is None:
            messagebox.showerror("Error", "No feature importance available")
            return
        
        timestamp = time.strftime("%Y%m%d_%H%M%S")
        default_name = f"feature_importance_{timestamp}.csv"
        
        filename = filedialog.asksaveasfilename(
            title="Export Feature Importance",
            filetypes=[("CSV Files", "*.csv")],
            defaultextension=".csv",
            initialname=default_name
        )
        
        if filename:
            try:
                importance_df.to_csv(filename, index=False)
                self.log_message(f"‚úÖ Feature importance exported: {filename}")
                messagebox.showinfo("Success", f"Feature importance exported successfully!\n{filename}")
            except Exception as e:
                error_msg = f"Failed to export feature importance: {str(e)}"
                self.log_message(f"‚ùå {error_msg}")
                messagebox.showerror("Error", error_msg)
    
    def export_complete_report(self):
        """Export complete analysis report."""
        timestamp = time.strftime("%Y%m%d_%H%M%S")
        default_name = f"complete_report_{timestamp}.txt"
        
        filename = filedialog.asksaveasfilename(
            title="Export Complete Report",
            filetypes=[("Text Files", "*.txt")],
            defaultextension=".txt",
            initialname=default_name
        )
        
        if filename:
            try:
                with open(filename, 'w') as f:
                    f.write("COMPREHENSIVE MULTI-CBUSH BOLT DETECTION ANALYSIS REPORT\n")
                    f.write("=" * 80 + "\n\n")
                    f.write(f"Generated: {time.strftime('%Y-%m-%d %H:%M:%S')}\n")
                    f.write("System: Multi-CBUSH Bolt Anomaly Detection System v2.0\n\n")
                    
                    # Dataset summary
                    f.write("DATASET SUMMARY\n")
                    f.write("-" * 40 + "\n")
                    summary = self.processor.get_study_summary()
                    f.write(f"Total Studies Processed: {summary.get('total_studies', 0)}\n")
                    f.write(f"Total Designs: {summary.get('total_designs', 0)}\n")
                    
                    for study_type, info in summary.get('by_type', {}).items():
                        f.write(f"{study_type.title()} Studies: {info['studies']} studies, {info['designs']} designs\n")
                    f.write("\n")
                    
                    # Matrix information
                    if hasattr(self, 'current_data') and self.current_data is not None:
                        f.write("MASTER MATRIX INFORMATION\n")
                        f.write("-" * 40 + "\n")
                        f.write(f"Matrix Type: {getattr(self, 'matrix_type', tk.StringVar(value='unknown')).get()}\n")
                        f.write(f"Total Designs: {len(self.current_data)}\n")
                        f.write(f"Features: {len([col for col in self.current_data.columns if col.startswith(('ACCE_', 'DISP_'))])}\n")
                        f.write(f"Classification Mode: {getattr(self.ml_pipeline, 'classification_mode', 'Unknown')}\n\n")
                    
                    # Model performance
                    if self.ml_pipeline.results:
                        f.write("MODEL PERFORMANCE RESULTS\n")
                        f.write("-" * 40 + "\n")
                        summary = self.ml_pipeline.create_results_summary()
                        
                        for model_name, metrics in summary.get('model_comparison', {}).items():
                            f.write(f"\n{model_name.upper()} MODEL:\n")
                            if summary.get('classification_mode') == 'multilabel':
                                f.write(f"   Jaccard Score (IoU): {metrics.get('jaccard_score', 0):.3f}\n")
                                f.write(f"   Hamming Loss: {metrics.get('hamming_loss', 0):.3f}\n")
                                f.write(f"   F1-Score (Macro): {metrics.get('f1_score', 0):.3f}\n")
                                f.write(f"   Exact Match Accuracy: {metrics.get('exact_match_accuracy', 0):.3f}\n")
                            else:
                                f.write(f"   Accuracy: {metrics.get('accuracy', 0):.3f}\n")
                    
                    f.write("\n\nSPACECRAFT DEPLOYMENT READINESS\n")
                    f.write("-" * 40 + "\n")
                    f.write("‚úÖ Multi-label classification capable\n")
                    f.write("‚úÖ Handles multiple simultaneous bolt failures\n")
                    f.write("‚úÖ Optimized for real-time monitoring\n")
                    f.write("‚úÖ Compatible with panel-mounted accelerometers\n")
                    f.write("‚úÖ Exportable models for offline deployment\n")
                    f.write("‚úÖ Comprehensive spatial analysis included\n")
                    f.write("\nSystem ready for operational spacecraft deployment!\n")
                
                self.log_message(f"‚úÖ Complete report exported: {filename}")
                messagebox.showinfo("Success", f"Complete report exported successfully!\n{filename}")
                
            except Exception as e:
                error_msg = f"Failed to export complete report: {str(e)}"
                self.log_message(f"‚ùå {error_msg}")
                messagebox.showerror("Error", error_msg)
    
    def log_message(self, message):
        """Log message to status display with timestamp."""
        timestamp = time.strftime("%H:%M:%S")
        log_entry = f"[{timestamp}] {message}\n"
        
        self.status_text.insert(tk.END, log_entry)
        self.status_text.see(tk.END)
        self.root.update_idletasks()


def main():
    """Main entry point for the enhanced GUI application."""
    root = tk.Tk()
    app = EnhancedBoltDetectionGUI(root)
    root.mainloop()


if __name__ == "__main__":
    main()